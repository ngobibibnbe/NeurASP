--------------/home/amngobibin/Bureau/NeurASP/examples/mnist/deepproblog
Training for 1 epochs (30000 iterations).
ok
Epoch 1
[[ 977    0    0    0    3    0    0    0    0    0]
 [1135    0    0    0    0    0    0    0    0    0]
 [1008    0    0    0   24    0    0    0    0    0]
 [1010    0    0    0    0    0    0    0    0    0]
 [ 969    0    0    0   13    0    0    0    0    0]
 [ 886    0    0    0    6    0    0    0    0    0]
 [ 957    0    0    0    1    0    0    0    0    0]
 [1028    0    0    0    0    0    0    0    0    0]
 [ 974    0    0    0    0    0    0    0    0    0]
 [1007    0    0    0    2    0    0    0    0    0]]
accuracy:  89.91
Iteration:  100 	Average Loss:  2.734294391414538
Iteration:  200 	Average Loss:  2.8191710909189065
Iteration:  300 	Average Loss:  2.7257846608568896
Iteration:  400 	Average Loss:  2.5942892349255118
Iteration:  500 	Average Loss:  2.5205198484380893
ok 500
[[873   0   1   7  93   0   3   3   0   0]
 [672   0   2  87 374   0   0   0   0   0]
 [747   0  66   7 211   0   0   0   1   0]
 [160   0   7  28 773   0   0  22  20   0]
 [  1   0   0   0 978   0   0   0   3   0]
 [ 18   0   2   4 799   0   0  12  57   0]
 [  4   0   2   0 952   0   0   0   0   0]
 [ 38   0   0   3 561   0   0  93 333   0]
 [ 21   0   0   3 879   0   0   1  70   0]
 [  2   0   0   0 930   0   0   2  75   0]]
accuracy:  89.91
Iteration:  600 	Average Loss:  2.434767740393151
Iteration:  700 	Average Loss:  2.3507208220002513
Iteration:  800 	Average Loss:  2.197880638323809
Iteration:  900 	Average Loss:  2.167757746832822
Iteration:  1000 	Average Loss:  1.699780601760061
ok 1000
[[ 866    2   19    0    0    1   57   18   10    7]
 [   0 1025   96    0    0    2    2    6    4    0]
 [   0    1  968    0    8   14    6   14   21    0]
 [   1    2  312  311   13  282    1   20   68    0]
 [   0    0   46    0  224  169  464    0   73    6]
 [   2    9   20    2    1  354  188   11  220   85]
 [   1    2   10    0    1    7  929    0    7    1]
 [   0   33   51    0    2    4    4  857   73    4]
 [   1   12   23    0    1   61  122   34  688   32]
 [   3    3    6    1    2   21  136   31  539  267]]
accuracy:  91.23
Iteration:  1100 	Average Loss:  1.6995561281716678
Iteration:  1200 	Average Loss:  1.0156156092910487
Iteration:  1300 	Average Loss:  0.9912106494843439
Iteration:  1400 	Average Loss:  1.0131085872850982
Iteration:  1500 	Average Loss:  0.9464111533605073
ok 1500
[[ 961    0    3    0    0    8    2    1    2    3]
 [   0 1111    4    9    7    0    0    0    4    0]
 [   1    0  991    7    4    3    0   18    6    2]
 [   0    0   37  902    2   54    0    6    3    6]
 [   0    0    5    0  914    6    1    0    1   55]
 [   4    0    4   49    7  812    1    0    5   10]
 [   7    1    9    0   60   91  785    0    5    0]
 [   2    5   57    5    3    3    0  927    4   22]
 [   1    1    9   31   12  155    0    6  634  125]
 [   3    4    2    2   30   36    0   14    4  914]]
accuracy:  96.82
Iteration:  1600 	Average Loss:  0.7376033052042608
Iteration:  1700 	Average Loss:  0.4922942889099178
Iteration:  1800 	Average Loss:  0.7673691774141085
Iteration:  1900 	Average Loss:  0.35894357252373665
Iteration:  2000 	Average Loss:  0.6089599263279518
ok 2000
[[ 958    0    4    0    0    4    9    1    4    0]
 [   0 1107    4   10    1    1    1    3    8    0]
 [   1    0 1001   10    1    0    0   15    4    0]
 [   0    0   15  952    0   20    0   19    4    0]
 [   0    1    3    0  939    0   15    6    3   15]
 [   4    1    1   11    0  851   14    3    6    1]
 [   1    3    0    0    2    5  945    0    2    0]
 [   0    3   39    3    0    2    1  979    1    0]
 [   2    0    5    7    6   45   15   16  875    3]
 [   4    2    1    4   22   38    4  153   26  755]]
accuracy:  97.27
Iteration:  2100 	Average Loss:  0.6411706657187467
Iteration:  2200 	Average Loss:  0.28284900449194805
Iteration:  2300 	Average Loss:  0.4245033706810869
Iteration:  2400 	Average Loss:  0.4044844474676787
Iteration:  2500 	Average Loss:  0.299190601751645
ok 2500
[[ 949    1    0    0    0   11    4    1    2   12]
 [   0 1124    2    3    2    0    4    0    0    0]
 [   7    4  976    9    0    1    0   26    9    0]
 [   2    4    7  909    0   34    0   31    8   15]
 [   0    7    2    0  933    0   13    0    1   26]
 [   4    2    0    5    0  834    2    2   10   33]
 [   8    2    0    0    9    6  930    0    3    0]
 [   0    5   20    0    0    0    0  981    1   21]
 [   4   10    2    5   16    8    4   16  835   74]
 [   1    7    0    2    9   11    2   10    0  967]]
accuracy:  97.77
Iteration:  2600 	Average Loss:  0.3970493238718415
Iteration:  2700 	Average Loss:  0.4827339604231577
Iteration:  2800 	Average Loss:  0.3665188926398877
Iteration:  2900 	Average Loss:  0.5382489861585227
Iteration:  3000 	Average Loss:  0.29875853366140004
ok 3000
[[ 967    1    4    0    0    1    0    1    1    5]
 [   1 1120    2    5    2    0    3    1    1    0]
 [   1    0 1011    2    0    0    0   15    3    0]
 [   0    0   11  974    0    9    0   10    5    1]
 [   0    1    6    0  971    0    1    1    1    1]
 [   5    0    2   26    1  846    3    1    7    1]
 [  13    3    8    0   25    2  904    0    3    0]
 [   0    4   31    4    0    0    0  979    1    9]
 [  16    1   10   10   12    9    5   17  873   21]
 [   3    4    0    7   35   19    0   18    3  920]]
accuracy:  98.72999999999999
Iteration:  3100 	Average Loss:  0.4541200547181182
Iteration:  3200 	Average Loss:  0.3676325227091101
Iteration:  3300 	Average Loss:  0.33666002144051227
Iteration:  3400 	Average Loss:  0.5231466828440066
Iteration:  3500 	Average Loss:  0.4099754938863193
ok 3500
[[ 973    2    0    0    0    2    0    0    3    0]
 [   0 1124    1    7    1    0    0    0    2    0]
 [   4    2  958   56    2    0    0    4    6    0]
 [   1    0    2  984    0   15    0    3    3    2]
 [   0    5    1    1  949    0    2    0    2   22]
 [   3    1    1    6    0  878    0    0    0    3]
 [  15    4    5    0   18   16  879    0   19    2]
 [   5   68   49   58    0    3    0  822    2   21]
 [   6    4    1   21    9    9    1    6  904   13]
 [   2   10    0    5   14   12    0    5    6  955]]
accuracy:  98.83
Iteration:  3600 	Average Loss:  0.3093740813761128
Iteration:  3700 	Average Loss:  0.26972830584709506
Iteration:  3800 	Average Loss:  0.21670889998809653
Iteration:  3900 	Average Loss:  0.2030567896001488
Iteration:  4000 	Average Loss:  0.2642456584527294
ok 4000
[[ 968    2    2    0    0    2    3    1    2    0]
 [   0 1131    2    0    1    0    0    0    1    0]
 [   3    5 1010    1    2    0    0    7    4    0]
 [   0    1    9  965    0   15    0   11    6    3]
 [   0    0    2    0  969    0    2    0    3    6]
 [   2    2    1    5    1  849    2    1   15   14]
 [   8    3    1    0   10    2  928    0    6    0]
 [   0    7   26    0    0    1    0  970    3   21]
 [   5    0    3    2    7    1    3    5  942    6]
 [   2    4    0    2   25    2    2    8    4  960]]
accuracy:  99.00999999999999
Iteration:  4100 	Average Loss:  0.22110219949727167
Iteration:  4200 	Average Loss:  0.2887297263015736
Iteration:  4300 	Average Loss:  0.26593266087174877
Iteration:  4400 	Average Loss:  0.36969726699890587
Iteration:  4500 	Average Loss:  0.40026911871275267
ok 4500
[[ 964    1    2    0    0    2    4    2    2    3]
 [   0 1116    2    2    1    1    9    3    1    0]
 [   2    1  984    8    1    0    0   24   12    0]
 [   0    0    1  985    0    9    0    9    4    2]
 [   0    0    0    0  946    0   27    1    4    4]
 [   2    0    1    9    0  868    3    1    4    4]
 [   9    1    0    0    2    1  944    0    1    0]
 [   0    3   10    6    0    2    0  990    2   15]
 [   2    0    2    5    7    1    8   10  931    8]
 [   1    3    0    3   25   11    2    9    6  949]]
accuracy:  99.03999999999999
Iteration:  4600 	Average Loss:  0.2504513422936099
Iteration:  4700 	Average Loss:  0.15672204245791238
Iteration:  4800 	Average Loss:  0.18524267843286904
Iteration:  4900 	Average Loss:  0.09862888802051632
Iteration:  5000 	Average Loss:  0.16000705183225628
ok 5000
[[ 971    1    0    0    0    0    4    1    3    0]
 [   0 1096    2    4    0    0   11    2   20    0]
 [   2    0 1000    8    0    0    0   11   11    0]
 [   0    0    1  994    0    1    0    5    8    1]
 [   0    3    2    0  883    0   25    3   14   52]
 [   2    0    1   40    0  820    3    0   22    4]
 [   5    1    0    0    1    0  947    0    4    0]
 [   0    2   17    9    0    0    0  973    9   18]
 [   2    0    1    3    1    1    3    0  963    0]
 [   2    0    0    8    3    6    2    7   30  951]]
accuracy:  98.67
Iteration:  5100 	Average Loss:  0.1457937936107143
Iteration:  5200 	Average Loss:  0.20956281901813528
Iteration:  5300 	Average Loss:  0.3608352936333415
Iteration:  5400 	Average Loss:  0.6308371096301343
Iteration:  5500 	Average Loss:  0.28538814562538883
ok 5500
[[ 969    0    2    0    1    2    2    2    2    0]
 [   0 1120    5    2    4    0    3    1    0    0]
 [   4    0 1000    8    2    0    0   16    2    0]
 [   1    0    1  985    0    6    0   13    2    2]
 [   0    0    1    0  974    0    1    1    0    5]
 [   2    0    1   15    1  863    2    2    1    5]
 [   7    2    6    0   13    9  920    0    1    0]
 [   0    1   13    0    2    1    0  998    2   11]
 [   3    0    5    5   14   12    3   15  857   60]
 [   2    2    0    3   23    2    1    9    0  967]]
accuracy:  98.75
Iteration:  5600 	Average Loss:  0.17939652286168795
Iteration:  5700 	Average Loss:  0.1258254482615435
Iteration:  5800 	Average Loss:  0.09780736549607924
Iteration:  5900 	Average Loss:  0.19317248680578605
Iteration:  6000 	Average Loss:  0.10374451503979631
ok 6000
[[ 970    0    0    0    0    2    4    1    2    1]
 [   0 1123    1    3    3    0    4    0    1    0]
 [  11    2 1001    3    1    0    0   10    4    0]
 [   2    0    2  966    1   16    0   14    8    1]
 [   0    0    0    0  976    0    2    0    0    4]
 [   3    0    1    1    0  885    2    0    0    0]
 [   4    2    0    0    6    6  940    0    0    0]
 [   1    5   16    0    1    2    0  996    2    5]
 [   5    0    1    1   10    7    9   10  920   11]
 [   3    4    0    2   24   19    1   11    2  943]]
accuracy:  99.11999999999999
Iteration:  6100 	Average Loss:  0.2012473571797816
Iteration:  6200 	Average Loss:  0.08528626418103567
Iteration:  6300 	Average Loss:  0.3210930132630495
Iteration:  6400 	Average Loss:  0.4332992141942114
Iteration:  6500 	Average Loss:  0.3600332193360881
ok 6500
[[ 973    0    2    0    0    0    1    1    3    0]
 [   1 1124    1    3    1    0    1    1    3    0]
 [   6    4 1003    6    0    0    0    4    9    0]
 [   1    0    1  992    0    1    0    7    8    0]
 [   0    1    3    0  954    0    3    2    3   16]
 [   8    0    1   47    1  785    1    0   32   17]
 [  17    4    3    0    4    1  909    0   20    0]
 [   0    3   24    8    0    0    0  980    3   10]
 [   4    1    1    2    2    0    1    1  951   11]
 [   2    3    0    7    9    0    1   10    6  971]]
accuracy:  99.08
Iteration:  6600 	Average Loss:  0.1751264610942072
Iteration:  6700 	Average Loss:  0.15376056572040964
Iteration:  6800 	Average Loss:  0.23209301304681515
Iteration:  6900 	Average Loss:  0.14152220553872294
Iteration:  7000 	Average Loss:  0.1617375769626305
ok 7000
[[ 975    0    1    0    0    0    2    1    1    0]
 [   1 1129    1    3    0    0    1    0    0    0]
 [   9    4 1004    5    0    0    0    6    4    0]
 [   1    0    1  999    1    1    0    5    2    0]
 [   0    1    1    0  978    0    0    0    2    0]
 [   4    0    1   13    3  866    4    0    0    1]
 [   6    4    1    0    8    0  937    0    2    0]
 [   1    3   21   16    1    1    0  976    5    4]
 [   6    3    2    5    8    0    1    3  940    6]
 [   2    9    0   13   30    2    1   13    3  936]]
accuracy:  99.16
Iteration:  7100 	Average Loss:  0.3173713618693429
Iteration:  7200 	Average Loss:  0.18576773879218986
Iteration:  7300 	Average Loss:  0.11656318334098727
Iteration:  7400 	Average Loss:  0.17646891273970552
Iteration:  7500 	Average Loss:  0.16668235096653017
ok 7500
[[ 973    0    0    0    0    0    1    1    4    1]
 [   0 1131    0    1    0    1    1    1    0    0]
 [   9    5  995    3    0    0    0   17    3    0]
 [   0    0    7  945    0   34    0   15    6    3]
 [   0    0    3    0  965    0    2    2    2    8]
 [   3    1    0    0    0  867   14    0    3    4]
 [   8    3    0    0    6    1  939    0    1    0]
 [   0    2   10    0    0    0    0 1001    2   13]
 [   5    1    1    1    3    4    1    4  942   12]
 [   2    4    0    1   12    3    0   10    5  972]]
accuracy:  99.22
Iteration:  7600 	Average Loss:  0.1359390222717446
Iteration:  7700 	Average Loss:  0.16590268900301158
Iteration:  7800 	Average Loss:  0.1848863213997051
Iteration:  7900 	Average Loss:  0.2062541009605093
Iteration:  8000 	Average Loss:  0.27442593795425035
ok 8000
[[ 961    0    0    1    0    3    1    2    3    9]
 [   1 1118    0    2    0    1    6    1    6    0]
 [   4    4  992    4    0    0    0   26    2    0]
 [   0    0    3  988    0    8    0    9    2    0]
 [   0    0    2    0  971    0    4    2    1    2]
 [   3    2    1    9    0  872    4    0    1    0]
 [   7    2    0    0    5    0  942    0    2    0]
 [   0    2    4    1    0    0    0 1020    1    0]
 [   5    0    1    3    2   11    1    8  934    9]
 [   1    3    0    5   17   10    2   24    1  946]]
accuracy:  99.17
Iteration:  8100 	Average Loss:  0.04059102156297387
Iteration:  8200 	Average Loss:  0.25050117422473395
Iteration:  8300 	Average Loss:  0.29429107908427715
Iteration:  8400 	Average Loss:  0.18990376394738498
Iteration:  8500 	Average Loss:  0.199478402578433
ok 8500
[[ 972    1    0    0    0    2    1    1    3    0]
 [   0 1130    0    2    0    0    1    0    2    0]
 [   3   13 1004    1    0    0    0    8    3    0]
 [   2    3    5  967    0   17    0    8    7    1]
 [   1    8    5    0  953    0    6    2    2    5]
 [   4    2    0    4    0  877    2    0    3    0]
 [   5    5    1    0    1    0  943    0    3    0]
 [   1    4   16    1    0    2    0  996    3    5]
 [   4    0    1    1    2    1    3    0  960    2]
 [   4    3    0    1   15   22    2    8    4  950]]
accuracy:  99.28
Iteration:  8600 	Average Loss:  0.36316856789622015
Iteration:  8700 	Average Loss:  0.16157204517624163
Iteration:  8800 	Average Loss:  0.1941789504606685
Iteration:  8900 	Average Loss:  0.12222018836575288
Iteration:  9000 	Average Loss:  0.21765048375153623
ok 9000
[[ 966    0    3    0    0    3    2    1    4    1]
 [   0 1109    4    2    1    2    2    4   11    0]
 [   5    0 1017    2    0    0    0    7    1    0]
 [   3    0    5  972    0   19    0    6    4    1]
 [   0    0    3    0  962    0    5    1    4    7]
 [   1    0    1    6    0  878    2    0    3    1]
 [   3    2    0    0    6    6  937    0    4    0]
 [   0    0   19    2    0    2    0 1001    2    2]
 [   3    0    1    1    3    3    4    4  955    0]
 [   1    1    0    2    7   15    1   13   16  953]]
accuracy:  99.32
Iteration:  9100 	Average Loss:  0.12949718071869845
Iteration:  9200 	Average Loss:  0.48758778268297
Iteration:  9300 	Average Loss:  0.10728143455716484
Iteration:  9400 	Average Loss:  0.23924176671186134
Iteration:  9500 	Average Loss:  0.1793395009624444
ok 9500
[[ 973    0    0    1    0    0    3    1    1    1]
 [   2 1122    2    2    0    1    1    1    4    0]
 [  21    0  993    2    0    0    0   14    2    0]
 [   3    0    1  992    0    6    0    5    3    0]
 [   3    0    2    0  929    0    3    0    3   42]
 [   4    0    0    8    0  861   10    0    4    5]
 [   8    2    0    0    3    1  940    0    4    0]
 [   0    0   11    2    0    0    0 1001    3   11]
 [   5    0    1    1    4    0    2    6  945   10]
 [   2    1    0    2    4    6    0    7    3  984]]
accuracy:  99.06
Iteration:  9600 	Average Loss:  0.16500011451701418
Iteration:  9700 	Average Loss:  0.1693264146303713
Iteration:  9800 	Average Loss:  0.18039909939528925
Iteration:  9900 	Average Loss:  0.3223787730099381
Writing snapshot to model_iter_10000.mdl
Iteration:  10000 	Average Loss:  0.19352058947346054
ok 10000
[[ 972    0    0    0    0    0    5    1    0    2]
 [   0 1128    0    4    1    1    1    0    0    0]
 [  10    8  985   12    3    1    3    8    2    0]
 [   2    0    2  981    0   14    0    5    5    1]
 [   0    5    0    0  964    0    5    1    2    5]
 [   4    0    0    5    0  872    9    0    1    1]
 [   3    3    0    0    1    2  948    0    1    0]
 [   2    6   10    6    1    2    0  988    3   10]
 [   5    1    1    2    5   10    7    3  931    9]
 [   1    4    0    1   17   11    2    7    1  965]]
accuracy:  99.28
Iteration:  10100 	Average Loss:  0.22764223911163672
Iteration:  10200 	Average Loss:  0.14433085833965856
Iteration:  10300 	Average Loss:  0.07903844405611808
Iteration:  10400 	Average Loss:  0.23030436801041304
Iteration:  10500 	Average Loss:  0.3293409647170151
ok 10500
[[ 973    0    0    0    0    0    5    1    1    0]
 [   0 1118    0    0    0    0    4    0   13    0]
 [  10    6  983    3    2    0    7   10   11    0]
 [   3    1    3  879    0  103    0   11    9    1]
 [   0    6    0    0  959    0    5    0    7    5]
 [   4    0    0    0    0  874   11    0    1    2]
 [   5    2    0    0    4    2  942    0    3    0]
 [   1    4    7    1    3    2    0  979    5   26]
 [   3    0    0    0    1    4    8    4  944   10]
 [   1    0    0    0   15    8    0    6    6  973]]
accuracy:  99.2
Iteration:  10600 	Average Loss:  0.22867840729981936
Iteration:  10700 	Average Loss:  0.1708917350015778
Iteration:  10800 	Average Loss:  0.27667853777000684
Iteration:  10900 	Average Loss:  0.17508193624501267
Iteration:  11000 	Average Loss:  0.079412251610086
ok 11000
[[ 978    0    0    0    0    0    1    1    0    0]
 [   0 1129    1    2    0    1    2    0    0    0]
 [  10    2 1004    2    0    0    2   10    2    0]
 [   3    1    3  972    0   15    0    9    6    1]
 [   0    3    9    0  939    0    6    9    8    8]
 [   2    0    0    3    0  870   16    0    1    0]
 [   7    3    0    0    1    1  945    0    1    0]
 [   1    7    9    0    1    1    0  993    3   13]
 [   5    0    1    1    1    2    4    5  951    4]
 [   2    3    0    0   12   18    1   14    7  952]]
accuracy:  99.17
Iteration:  11100 	Average Loss:  0.1443702482044803
Iteration:  11200 	Average Loss:  0.12850317716914325
Iteration:  11300 	Average Loss:  0.0822714067350165
Iteration:  11400 	Average Loss:  0.2572565845408569
Iteration:  11500 	Average Loss:  0.1531105601637959
ok 11500
[[ 973    0    0    0    0    2    2    2    1    0]
 [   0 1118    0    2    0    1    4    0   10    0]
 [   4    3 1002    3    0    0    0   11    9    0]
 [   0    0    0  959    0   25    0   16    9    1]
 [   0    0    0    0  971    0    2    1    2    6]
 [   2    0    0    4    0  860   12    4    9    1]
 [   3    1    0    0    3    2  945    0    4    0]
 [   0    2    6    0    0    0    0 1012    3    5]
 [   3    0    1    0    6    1    2    7  952    2]
 [   3    3    0    0   17    7    0   21    4  954]]
accuracy:  99.3
Iteration:  11600 	Average Loss:  0.1987308975755626
Iteration:  11700 	Average Loss:  0.33569338527116194
Iteration:  11800 	Average Loss:  0.080874932794456
Iteration:  11900 	Average Loss:  0.3945952604383068
Iteration:  12000 	Average Loss:  0.13278374339911964
ok 12000
[[ 965    1    0    0    0    0   11    1    1    1]
 [   0 1129    0    2    0    0    4    0    0    0]
 [   2    6  987    5    2    0    7   21    2    0]
 [   2    0    1  987    0    5    0    8    6    1]
 [   0    0    0    0  967    0    6    1    3    5]
 [   2    1    0    5    1  799   65    0   17    2]
 [   0    4    0    0    1    1  951    0    1    0]
 [   0    7    4    0    1    0    0 1005    3    8]
 [   4    2    1    1    3    0   11    4  947    1]
 [   1    7    0    1   18    1    1    8    8  964]]
accuracy:  99.37
Iteration:  12100 	Average Loss:  0.163488754155581
Iteration:  12200 	Average Loss:  0.17317348088346438
Iteration:  12300 	Average Loss:  0.20769197031083902
Iteration:  12400 	Average Loss:  0.11632544713734827
Iteration:  12500 	Average Loss:  0.24146927919556113
ok 12500
[[ 972    2    0    0    0    0    1    1    2    2]
 [   0 1131    0    3    0    1    0    0    0    0]
 [   3    3  999    1    0    0    0   25    1    0]
 [   2    0    2  981    0    7    0   14    3    1]
 [   0    0    0    0  923    0    0    4    3   52]
 [   2    0    0    4    0  854   21    0    7    4]
 [   5    4    0    0    1    1  944    0    3    0]
 [   1    1    2    0    0    1    0 1019    1    3]
 [   5    1    1    1    4    1    1    5  949    6]
 [   2    1    0    1    2    3    0   19    0  981]]
accuracy:  99.03999999999999
Iteration:  12600 	Average Loss:  0.20711897816585542
Iteration:  12700 	Average Loss:  0.13138044458797654
Iteration:  12800 	Average Loss:  0.10901613691341037
Iteration:  12900 	Average Loss:  0.22856831814969136
Iteration:  13000 	Average Loss:  0.2564990571373577
ok 13000
[[ 976    0    1    0    0    0    2    0    1    0]
 [   4 1110   13    3    0    0    1    1    3    0]
 [   5    0 1025    0    0    0    0    1    1    0]
 [   3    0    9  995    0    0    0    1    2    0]
 [   1    0    3    0  968    0    4    0    3    3]
 [   2    0    1   60    0  796    5    1   24    3]
 [  14    1    1    0    3    1  935    0    3    0]
 [   3    0   35    1    1    0    0  980    5    3]
 [   6    0    8    2    3    0    1    2  951    1]
 [   6    0    0    4   16    1    0    8   11  963]]
accuracy:  99.44
Iteration:  13100 	Average Loss:  0.2592923624667912
Iteration:  13200 	Average Loss:  0.23981784538138473
Iteration:  13300 	Average Loss:  0.24539626132779171
Iteration:  13400 	Average Loss:  0.25832860849633926
Iteration:  13500 	Average Loss:  0.14586929121596637
ok 13500
[[ 962    0    0    0    0    0    6    1    2    9]
 [   0 1133    0    1    0    0    0    0    1    0]
 [   3   12  985    3    1    0    0   26    2    0]
 [   3    1    0  985    0    7    0    9    4    1]
 [   0    0    0    0  976    0    0    1    1    4]
 [   2    0    0    6    2  860    5    0   15    2]
 [   2    3    0    0    9    1  935    0    8    0]
 [   0    7    3    0    2    0    0 1009    2    5]
 [   3    0    1    1    6    0    0    4  957    2]
 [   0    0    0    0   36    2    1    9    5  956]]
accuracy:  99.24
Iteration:  13600 	Average Loss:  0.164455043941281
Iteration:  13700 	Average Loss:  0.19707811079701648
Iteration:  13800 	Average Loss:  0.30184077150050986
Iteration:  13900 	Average Loss:  0.15132484182064668
Iteration:  14000 	Average Loss:  0.14298763501939274
ok 14000
[[ 949    0    2    0    0    0   10    2    8    9]
 [   0 1114    1    3    1    0    4    1   11    0]
 [   0    2 1021    0    0    0    0    7    2    0]
 [   0    1   11  982    0    8    0    5    3    0]
 [   0    0    3    0  961    0    0    1    5   12]
 [   1    0    0    3    0  871    7    0    8    2]
 [   2    1    0    0    5    1  943    0    6    0]
 [   0    1   15    1    0    0    0 1004    2    5]
 [   1    0    6    1    1    0    0    4  956    5]
 [   0    0    1    1    5    3    0    9    3  987]]
accuracy:  99.45
Iteration:  14100 	Average Loss:  0.2580670439628048
Iteration:  14200 	Average Loss:  0.1743198418835152
Iteration:  14300 	Average Loss:  0.19406072989262024
Iteration:  14400 	Average Loss:  0.04593107918067251
Iteration:  14500 	Average Loss:  0.2126289027887572
ok 14500
[[ 958    0    4    0    0    0    8    0    9    1]
 [   0 1113    4    2    0    0    3    0   13    0]
 [   0    0 1027    1    0    0    0    1    3    0]
 [   0    0    5  990    0    8    0    2    4    1]
 [   0    1    2    0  958    0    0    1    6   14]
 [   0    0    1    5    0  867    3    0   15    1]
 [   1    2    0    0    1    3  945    0    6    0]
 [   0    2   25    1    3    0    0  985    3    9]
 [   0    0    1    1    1    0    0    0  970    1]
 [   1    0    1    3    5    2    0    8   11  978]]
accuracy:  99.42
Iteration:  14600 	Average Loss:  0.16280703841846114
Iteration:  14700 	Average Loss:  0.11204924644716939
Iteration:  14800 	Average Loss:  0.14885353577272253
Iteration:  14900 	Average Loss:  0.07834336198749324
Iteration:  15000 	Average Loss:  0.09975626246572833
ok 15000
[[ 966    1    0    0    0    0   11    1    1    0]
 [   0 1125    2    2    0    1    3    0    2    0]
 [   5    0 1011    0    2    0    0   12    2    0]
 [   2    0    4  979    1   10    0   11    3    0]
 [   0    1    0    0  976    0    2    0    2    1]
 [   2    0    0    4    1  869   14    0    2    0]
 [   6    2    0    0    1    1  947    0    1    0]
 [   0    2    6    0    6    0    0 1011    1    2]
 [   2    0    2    3    2    3   10    4  946    2]
 [   2    0    0    2   26    4    0   13    8  954]]
accuracy:  99.4
Iteration:  15100 	Average Loss:  0.19651862542305515
Iteration:  15200 	Average Loss:  0.10990869457377458
Iteration:  15300 	Average Loss:  0.39996394324463647
Iteration:  15400 	Average Loss:  0.144249648620672
Iteration:  15500 	Average Loss:  0.197465233279773
ok 15500
[[ 977    0    1    0    0    0    1    1    0    0]
 [   0 1134    0    0    0    0    0    0    1    0]
 [   4    5  996    2    1    0    0   22    2    0]
 [   2    1    2  988    0    2    0   10    2    3]
 [   0    2    0    0  973    0    0    1    2    4]
 [   4    0    0    6    0  864    2    0    5   11]
 [  12    6    0    0    8    1  926    0    5    0]
 [   0    6    5    0    5    0    0 1007    2    3]
 [   3    0    2    1    2    0    0    2  960    4]
 [   3    2    0    1   12    1    0   13    4  973]]
accuracy:  99.39
Iteration:  15600 	Average Loss:  0.21603469025708108
Iteration:  15700 	Average Loss:  0.15644313526568943
Iteration:  15800 	Average Loss:  0.07966888455672615
Iteration:  15900 	Average Loss:  0.255527175712018
Iteration:  16000 	Average Loss:  0.14211284870014126
ok 16000
[[ 976    0    0    0    0    0    0    0    4    0]
 [   0 1054    0    4    2    2    2    1   70    0]
 [   7    4 1007    0    0    0    1    6    7    0]
 [   1    0    2  981    0   14    0    6    5    1]
 [   0    0    0    0  968    0    0    1    1   12]
 [   1    0    0    4    0  875    2    0    7    3]
 [   6    1    0    0    7    4  927    0   13    0]
 [   0    2   13    1    1    0    0 1004    3    4]
 [   2    0    1    1    2    0    0    0  951   17]
 [   2    2    0    0    2    3    1   10    4  985]]
accuracy:  99.39
Iteration:  16100 	Average Loss:  0.2121976002960875
Iteration:  16200 	Average Loss:  0.1702695474952473
Iteration:  16300 	Average Loss:  0.3938354972548241
Iteration:  16400 	Average Loss:  0.15840453027402174
Iteration:  16500 	Average Loss:  0.18624513303595008
ok 16500
[[ 971    0    0    0    0    0    6    1    1    1]
 [   0 1099    0    4    1    4    6    1   20    0]
 [  12    2  963    9    8    1    8   16   13    0]
 [   2    0    0  987    0   13    0    2    4    2]
 [   1    0    0    0  968    0    2    0    1   10]
 [   1    0    0    3    0  885    1    0    1    1]
 [   3    1    0    0    2    6  943    0    3    0]
 [   0    2    3    2    2    2    0 1002    2   13]
 [   3    0    1    1    5    1    2    0  955    6]
 [   2    0    0    1    5   12    1    5    4  979]]
accuracy:  99.37
Iteration:  16600 	Average Loss:  0.10668691916164835
Iteration:  16700 	Average Loss:  0.07963791818614369
Iteration:  16800 	Average Loss:  0.13090871285377623
Iteration:  16900 	Average Loss:  0.25287827352168785
Iteration:  17000 	Average Loss:  0.25351228553240274
ok 17000
[[ 969    0    0    0    0    2    3    1    1    4]
 [   0 1134    0    1    0    0    0    0    0    0]
 [   1    9 1016    1    0    0    1    4    0    0]
 [   2    1    2  994    0    7    0    1    2    1]
 [   0    4    3    0  955    0    1    0    7   12]
 [   1    0    0   10    0  869    2    1    7    2]
 [   5    7    0    0    1    2  934    0    9    0]
 [   0   10   39    2    2    3    0  969    2    1]
 [   5    2    5    1    2    0    2    1  954    2]
 [   1    2    0    1    5    6    1    8   22  963]]
accuracy:  99.32
Iteration:  17100 	Average Loss:  0.14949757356922314
Iteration:  17200 	Average Loss:  0.08278952934665063
Iteration:  17300 	Average Loss:  0.19441823814803416
Iteration:  17400 	Average Loss:  0.11309057018411134
Iteration:  17500 	Average Loss:  0.2300008950150494
ok 17500
[[ 968    0    0    0    0    0    0    8    1    3]
 [   0 1103    1    1    0    0    1   22    7    0]
 [   0    0 1008    0    0    0    0   21    3    0]
 [   3    0    7  965    0   13    0   17    3    2]
 [   1    0    0    0  971    0    0    0    1    9]
 [   2    0    0    2    0  884    1    2    1    0]
 [  10    1    1    0    4    8  914    0   20    0]
 [   0    0   11    0    1    0    0 1015    1    0]
 [   4    0    2    1    7    1    0    7  945    7]
 [   2    0    1    0    8    4    0   21    2  971]]
accuracy:  99.41
Iteration:  17600 	Average Loss:  0.16430575245796294
Iteration:  17700 	Average Loss:  0.1615185936610953
Iteration:  17800 	Average Loss:  0.13607911381959448
Iteration:  17900 	Average Loss:  0.07256232089494069
Iteration:  18000 	Average Loss:  0.22509178176534314
ok 18000
[[ 926    0    0    0    0    1   46    2    1    4]
 [   0 1119    0    3    0    0    3    4    6    0]
 [   0    1 1019    0    0    0    2    7    3    0]
 [   0    0    5  996    0    3    0    3    2    1]
 [   0    1    0    0  946    0    6    2    3   24]
 [   1    0    0    9    0  874    6    1    1    0]
 [   0    2    0    0    1    3  950    0    2    0]
 [   0    0   14    2    1    0    0 1006    2    3]
 [   1    0    2    2    4    7    5    6  942    5]
 [   1    1    0    0    2   11    2   10    1  981]]
accuracy:  99.35000000000001
Iteration:  18100 	Average Loss:  0.22729806834789681
Iteration:  18200 	Average Loss:  0.1095231315136172
Iteration:  18300 	Average Loss:  0.10255659832515322
Iteration:  18400 	Average Loss:  0.291016977830208
Iteration:  18500 	Average Loss:  0.14100839869231752
ok 18500
[[ 969    0    0    1    0    1    3    1    5    0]
 [   1 1114    0    3    0    3    3    6    5    0]
 [   1    0 1012    2    2    0    0    8    7    0]
 [   1    0    4  996    0    6    0    0    3    0]
 [   0    0    0    0  974    0    1    1    1    5]
 [   1    0    0    6    0  878    3    1    2    1]
 [   3    2    0    0    4    6  938    0    5    0]
 [   0    0    6    1    1    1    0 1013    2    4]
 [   1    0    0    2    6    2    1    4  955    3]
 [   2    0    0    1    5   12    0    9    3  977]]
accuracy:  99.55000000000001
Iteration:  18600 	Average Loss:  0.059680675441507
Iteration:  18700 	Average Loss:  0.20365701897258784
Iteration:  18800 	Average Loss:  0.11290694581443733
Iteration:  18900 	Average Loss:  0.03912989698418397
Iteration:  19000 	Average Loss:  0.15269550547337046
ok 19000
[[ 973    0    2    0    0    0    0    1    3    1]
 [   0 1119    1    3    0    0    1    2    9    0]
 [   0    0 1015    5    2    0    0    5    5    0]
 [   0    0    4 1000    0    3    0    1    2    0]
 [   0    0    0    0  972    0    0    0    0   10]
 [   1    0    0    9    0  875    1    1    4    1]
 [   2    3    1    0    5    7  937    0    3    0]
 [   0    1    8    1    1    1    0 1008    4    4]
 [   3    0    1    1    8    2    0    3  956    0]
 [   1    0    0    2   12    1    0    8   18  967]]
accuracy:  99.42
Iteration:  19100 	Average Loss:  0.15604181904103823
Iteration:  19200 	Average Loss:  0.11247588497285178
Iteration:  19300 	Average Loss:  0.17412585438198713
Iteration:  19400 	Average Loss:  0.14364054918744387
Iteration:  19500 	Average Loss:  0.04255748676711251
ok 19500
[[ 966    1    2    0    1    0    7    1    2    0]
 [   0 1125    1    3    0    2    1    0    2    1]
 [   0    1 1002    9    2    0    0   11    7    0]
 [   0    0    1 1003    0    1    0    4    1    0]
 [   0    1    0    0  970    0    0    0    0   11]
 [   0    0    0   14    0  872    3    1    2    0]
 [   1    3    0    0    5    4  943    0    2    0]
 [   0    2    2    0    1    1    0 1008    5    9]
 [   2    0    1    2    8    2    0    4  955    0]
 [   2    0    0    4    9   11    1    7   21  954]]
accuracy:  99.24
Iteration:  19600 	Average Loss:  0.17366626761511475
Iteration:  19700 	Average Loss:  0.3069338301945852
Iteration:  19800 	Average Loss:  0.21750745154287995
Iteration:  19900 	Average Loss:  0.10015958981761487
Writing snapshot to model_iter_20000.mdl
Iteration:  20000 	Average Loss:  0.2853573235081373
ok 20000
[[ 975    0    1    0    0    0    2    0    1    1]
 [   0 1123    1    2    1    0    6    0    2    0]
 [   0    1 1022    2    2    0    0    5    0    0]
 [   1    0    2  997    0    1    0    5    3    1]
 [   0    0    0    0  981    0    0    0    0    1]
 [   1    0    0    5    0  862   11    1   11    1]
 [   3    1    0    0    3    1  948    0    2    0]
 [   0    4   12    0    1    0    0 1005    1    5]
 [   3    0    8    3    9    1    3    3  942    2]
 [   2    0    1    2   33    2    1    7    3  958]]
accuracy:  99.38
Iteration:  20100 	Average Loss:  0.14574965842604787
Iteration:  20200 	Average Loss:  0.1702686545850275
Iteration:  20300 	Average Loss:  0.06373423472465953
Iteration:  20400 	Average Loss:  0.15728255204564862
Iteration:  20500 	Average Loss:  0.13437750082053712
ok 20500
[[ 970    0    3    0    0    0    2    1    2    2]
 [   0 1130    0    3    0    0    2    0    0    0]
 [   0    1 1021    1    0    0    0    8    1    0]
 [   0    0    3  996    0    5    0    3    3    0]
 [   0    1    1    0  942    0    2    2    2   32]
 [   1    0    0    4    0  867   10    0    9    1]
 [   1    2    0    0    2    1  951    0    1    0]
 [   0    4    5    0    0    1    0 1009    1    8]
 [   2    0    2    1    2    0    0    3  958    6]
 [   1    2    0    1    4    9    1    7    4  980]]
accuracy:  99.22
Iteration:  20600 	Average Loss:  0.07931448523104721
Iteration:  20700 	Average Loss:  0.11734204814291845
Iteration:  20800 	Average Loss:  0.14383515034200173
Iteration:  20900 	Average Loss:  0.253305738278956
Iteration:  21000 	Average Loss:  0.20822989707732947
ok 21000
[[ 973    2    3    0    0    0    1    0    0    1]
 [   0 1134    0    1    0    0    0    0    0    0]
 [   0    2 1025    0    0    0    0    3    2    0]
 [   2    1    3  994    0    4    0    5    1    0]
 [   0    7    0    0  963    0    0    3    0    9]
 [   2    0    0    9    0  875    5    0    1    0]
 [  12    4    0    0    2    1  939    0    0    0]
 [   1    4   17    0    1    0    0 1003    1    1]
 [   9    2    2    2    4    2    1    8  934   10]
 [   1    4    0    3    4    5    1   21    1  969]]
accuracy:  99.39
Iteration:  21100 	Average Loss:  0.2769224987570549
Iteration:  21200 	Average Loss:  0.12218455558689226
Iteration:  21300 	Average Loss:  0.1568520223895197
Iteration:  21400 	Average Loss:  0.09901229420435607
Iteration:  21500 	Average Loss:  0.055855005583337745
ok 21500
[[ 976    0    1    0    0    0    1    1    1    0]
 [   0 1117    1    1    0    3    1    2   10    0]
 [   1    1 1018    1    0    0    2    5    4    0]
 [   1    0    1  980    0   15    0    3    9    1]
 [   0    2    2    0  956    0    1    3    9    9]
 [   1    0    0    1    0  880    1    1    8    0]
 [   9    2    0    0    2    8  924    0   13    0]
 [   0    4   10    0    0    0    0 1009    3    2]
 [   2    0    1    0    0    1    0    0  969    1]
 [   1    2    0    1    6    9    0   11   14  965]]
accuracy:  99.42999999999999
Iteration:  21600 	Average Loss:  0.2763192994872972
Iteration:  21700 	Average Loss:  0.043545925109258164
Iteration:  21800 	Average Loss:  0.12128762829892402
Iteration:  21900 	Average Loss:  0.1003624143984971
Iteration:  22000 	Average Loss:  0.16171727127124458
ok 22000
[[ 962    3    2    1    2    0    2    8    0    0]
 [   0 1134    0    1    0    0    0    0    0    0]
 [   0    4 1015    5    0    0    0    6    2    0]
 [   1    0    1 1004    0    0    0    4    0    0]
 [   0    3    0    1  970    0    0    1    1    6]
 [   1    1    0   25    0  858    4    1    1    1]
 [   5    6    0    0    8    6  931    0    2    0]
 [   0    4    7    1    0    0    0 1011    1    4]
 [   1    3    2   11    4    6    1    5  925   16]
 [   0    5    0   12   12    1    1   10    1  967]]
accuracy:  99.31
Iteration:  22100 	Average Loss:  0.20681103370479137
Iteration:  22200 	Average Loss:  0.11299146643811447
Iteration:  22300 	Average Loss:  0.16834977419921915
Iteration:  22400 	Average Loss:  0.22516332133006
Iteration:  22500 	Average Loss:  0.2020692413589659
ok 22500
[[ 966    0    3    2    0    0    6    0    2    1]
 [   0 1114    0    3    1    2    7    2    6    0]
 [   0    1 1027    1    0    0    0    2    1    0]
 [   0    0    1 1005    0    1    0    3    0    0]
 [   0    0    0    0  947    0    0    0    2   33]
 [   1    0    0   28    0  856    4    1    2    0]
 [   2    2    0    0    5    2  946    0    1    0]
 [   0    2   11    3    0    0    0  995    1   16]
 [   1    0    2    9    1    5    1    4  944    7]
 [   0    1    0    6    3    1    0    7    1  990]]
accuracy:  99.24
Iteration:  22600 	Average Loss:  0.15438988883355453
Iteration:  22700 	Average Loss:  0.10211981442420998
Iteration:  22800 	Average Loss:  0.14069361813859346
Iteration:  22900 	Average Loss:  0.1734911503327181
Iteration:  23000 	Average Loss:  0.09824637947472917
ok 23000
[[ 973    0    1    0    1    1    1    1    1    1]
 [   0 1105    1    2    5    0   16    2    4    0]
 [   0    0 1024    0    1    0    1    6    0    0]
 [   1    0    0  994    0    7    0    6    2    0]
 [   0    0    0    0  972    0    0    0    1    9]
 [   2    0    0    3    0  881    2    1    3    0]
 [   5    0    0    0    8    3  940    0    2    0]
 [   0    2    8    1    2    0    0 1008    0    7]
 [   3    0    2    5    3    3    2    5  948    3]
 [   1    1    0    0   10    2    1   10    0  984]]
accuracy:  99.55000000000001
Iteration:  23100 	Average Loss:  0.16946150521967937
Iteration:  23200 	Average Loss:  0.13524811697044956
Iteration:  23300 	Average Loss:  0.27588862860002317
Iteration:  23400 	Average Loss:  0.28942577298395716
Iteration:  23500 	Average Loss:  0.12864752903379
ok 23500
[[ 962    0    2    0    1    1    3    1    2    8]
 [   0 1124    1    1    0    1    4    0    4    0]
 [   0    1 1021    0    1    0    2    5    2    0]
 [   0    0    0 1000    0    0    0    5    4    1]
 [   0    1    0    0  964    0    2    3    3    9]
 [   1    0    0   21    0  857    1    1    5    6]
 [   2    1    0    0    2    5  945    0    3    0]
 [   0    3    5    0    1    0    0 1004    2   13]
 [   1    0    1    1    0    0    2    5  959    5]
 [   0    0    0    1    5    1    0    5    2  995]]
accuracy:  99.44
Iteration:  23600 	Average Loss:  0.22155889385096705
Iteration:  23700 	Average Loss:  0.07398981044322028
Iteration:  23800 	Average Loss:  0.2016133673695102
Iteration:  23900 	Average Loss:  0.18057492671788214
Iteration:  24000 	Average Loss:  0.1883830156585018
ok 24000
[[ 972    0    1    0    1    0    2    1    2    1]
 [   0 1109    1    1    1    4    9    0    9    1]
 [   0    0 1022    2    2    1    2    2    1    0]
 [   2    0    1  980    0   23    0    1    2    1]
 [   0    0    0    0  974    0    1    0    3    4]
 [   1    0    0    1    0  883    1    1    5    0]
 [   3    1    0    0    6    6  936    0    6    0]
 [   0    2   12    2    0    2    0  949    5   56]
 [   3    0    2    1    0    0    2    0  966    0]
 [   2    0    0    0    8    5    0    1   10  983]]
accuracy:  99.11
Iteration:  24100 	Average Loss:  0.2234898375956044
Iteration:  24200 	Average Loss:  0.13084520222147966
Iteration:  24300 	Average Loss:  0.07907865182330341
Iteration:  24400 	Average Loss:  0.027017247892047222
Iteration:  24500 	Average Loss:  0.2218281378393492
ok 24500
[[ 972    1    1    0    1    0    2    2    0    1]
 [   0 1130    0    1    0    1    3    0    0    0]
 [   0    1 1017    8    0    1    0    3    2    0]
 [   2    0    1  995    0    7    0    4    1    0]
 [   0    0    0    0  964    0    0    0    2   16]
 [   1    0    0    2    0  885    3    1    0    0]
 [   3    1    0    0    4    5  944    0    1    0]
 [   0    2    5    1    0    2    0 1001    2   15]
 [   6    0    1    2    0    6    2    4  947    6]
 [   1    0    0    1    6    4    0    7    2  988]]
accuracy:  99.41
Iteration:  24600 	Average Loss:  0.06255970595972193
Iteration:  24700 	Average Loss:  0.204019380746346
Iteration:  24800 	Average Loss:  0.34126448023849293
Iteration:  24900 	Average Loss:  0.19512908608083318
Iteration:  25000 	Average Loss:  0.09064878859328784
ok 25000
[[ 976    0    2    0    1    0    1    0    0    0]
 [   0 1132    0    3    0    0    0    0    0    0]
 [   0    2 1019    3    2    0    2    4    0    0]
 [   1    0    3  995    0    6    0    4    1    0]
 [   0   14    0    0  956    0    0    0    3    9]
 [   1    0    0    7    0  879    2    2    1    0]
 [   5    3    0    0    3    3  940    0    4    0]
 [   0    2    5    5    0    0    0 1013    1    2]
 [   6    1    7    3    0    0    1    4  949    3]
 [   3    3    0    2    6    3    1   16    2  973]]
accuracy:  99.5
Iteration:  25100 	Average Loss:  0.08254417838177881
Iteration:  25200 	Average Loss:  0.09762341843864121
Iteration:  25300 	Average Loss:  0.2882674892419162
Iteration:  25400 	Average Loss:  0.10792276603055967
Iteration:  25500 	Average Loss:  0.17968199203263313
ok 25500
[[ 977    0    2    0    0    0    1    0    0    0]
 [   0 1126    1    6    0    1    1    0    0    0]
 [   0    1 1018    6    0    0    0    7    0    0]
 [   0    0    1 1002    0    3    0    4    0    0]
 [   0    2    0    0  970    0    0    0    2    8]
 [   1    0    0   12    0  878    1    0    0    0]
 [   6    3    1    0    4   10  933    0    1    0]
 [   1    2    6    3    0    0    0  999    1   16]
 [   9    1   10   14    2   11    0    4  913   10]
 [   3    0    0    2    8    6    0    3    0  987]]
accuracy:  99.44
Iteration:  25600 	Average Loss:  0.16192793197333205
Iteration:  25700 	Average Loss:  0.17830150186072885
Iteration:  25800 	Average Loss:  0.12961403578829955
Iteration:  25900 	Average Loss:  0.168880367877553
Iteration:  26000 	Average Loss:  0.28494842315101204
ok 26000
[[ 973    0    2    0    0    1    3    1    0    0]
 [   0 1130    1    0    0    1    1    1    1    0]
 [   0    4 1021    0    0    0    0    5    2    0]
 [   0    0    2  966    0   31    0    5    5    1]
 [   0    5    0    0  957    0    3    2    2   13]
 [   1    0    0    1    0  879   11    0    0    0]
 [   2    2    0    0    1    3  949    0    1    0]
 [   0    2    7    0    0    2    0 1016    1    0]
 [   2    0    1    0    0    6    6    4  954    1]
 [   1    1    0    1    5   24    1   10    2  964]]
accuracy:  99.4
Iteration:  26100 	Average Loss:  0.1562495922296527
Iteration:  26200 	Average Loss:  0.10504384517332116
Iteration:  26300 	Average Loss:  0.455482027285012
Iteration:  26400 	Average Loss:  0.07320100904155315
Iteration:  26500 	Average Loss:  0.39763135038554437
ok 26500
[[ 969    0    5    0    0    0    4    0    2    0]
 [   1 1122    2    0    0    1    7    1    1    0]
 [   0    0 1032    0    0    0    0    0    0    0]
 [   0    0   15  988    0    5    0    1    1    0]
 [   0    0    4    0  975    0    0    0    1    2]
 [   2    0    2    7    0  865   13    0    3    0]
 [   3    1    1    0    4    0  949    0    0    0]
 [   0    1   51    3    0    0    0  961    2   10]
 [   3    0   16    2    1    1    5    1  945    0]
 [   3    0    1    1   16    9    0    4   11  964]]
accuracy:  99.42999999999999
Iteration:  26600 	Average Loss:  0.1505790770065442
Iteration:  26700 	Average Loss:  0.15462974129724516
Iteration:  26800 	Average Loss:  0.1896923513554746
Iteration:  26900 	Average Loss:  0.05156569831807333
Iteration:  27000 	Average Loss:  0.09090468977343248
ok 27000
[[ 963    0    0    1    3    0    2    4    2    5]
 [   1 1123    0    2    0    1    3    0    5    0]
 [   0    2  993   17    5    0    0   13    2    0]
 [   0    0    0 1007    0    1    0    0    1    1]
 [   0    0    0    0  972    0    0    1    2    7]
 [   1    0    1   26    0  857    4    1    2    0]
 [   2    1    0    1    9    1  941    0    3    0]
 [   0    3    0    6    0    0    0 1007    2   10]
 [   2    0    3    2    0    0    2    1  964    0]
 [   1    0    0    1    7    3    0    6    7  984]]
accuracy:  99.52
Iteration:  27100 	Average Loss:  0.14783058135638302
Iteration:  27200 	Average Loss:  0.14166218476107406
Iteration:  27300 	Average Loss:  0.049828431192906274
Iteration:  27400 	Average Loss:  0.08246251417188281
Iteration:  27500 	Average Loss:  0.30013900089323525
ok 27500
[[ 977    0    0    0    0    0    1    0    2    0]
 [   1 1126    0    0    0    3    4    0    1    0]
 [   2    5 1012    4    0    0    5    3    1    0]
 [   1    1    2 1003    0    1    0    0    2    0]
 [   0    1    1    1  956    0   14    1    2    6]
 [   1    0    0   12    0  873    4    0    2    0]
 [   5    1    0    0    1    2  947    0    2    0]
 [   1    4    6   10    0    1    0  992    7    7]
 [   3    0    2    1    0    0    2    0  966    0]
 [   2    0    0    6    6    7    2    5   18  963]]
accuracy:  99.41
Iteration:  27600 	Average Loss:  0.15548550599850122
Iteration:  27700 	Average Loss:  0.0871846431948069
Iteration:  27800 	Average Loss:  0.15829098631153551
Iteration:  27900 	Average Loss:  0.02026240162899308
Iteration:  28000 	Average Loss:  0.18860786476109895
ok 28000
[[ 962    0    0    0    0    0   16    0    0    2]
 [   1 1127    0    1    0    2    3    0    1    0]
 [   0    1 1027    1    0    0    0    3    0    0]
 [   1    0    2  999    0    4    0    0    2    2]
 [   0    4    1    0  962    0    8    0    1    6]
 [   1    0    0    9    0  873    7    0    2    0]
 [   1    2    0    0    1    1  952    0    1    0]
 [   1    2   10    6    0    1    0  993    2   13]
 [   4    0    4    1    0    0   13    0  951    1]
 [   3    0    0    2   13    3    2    4    7  975]]
accuracy:  99.42
Iteration:  28100 	Average Loss:  0.19791662219056963
Iteration:  28200 	Average Loss:  0.22915070203234136
Iteration:  28300 	Average Loss:  0.054493732777316166
Iteration:  28400 	Average Loss:  0.09388804860699933
Iteration:  28500 	Average Loss:  0.07049748327373587
ok 28500
[[ 946    1    2    0    4    0   10    7    1    9]
 [   0 1128    0    2    0    2    1    1    1    0]
 [   0    1 1015    0    2    0    0   13    1    0]
 [   1    0    1  996    0    2    0    8    1    1]
 [   0    1    0    0  979    0    0    0    0    2]
 [   1    0    0   12    0  861    7    1    0   10]
 [   1    3    0    0    3    1  949    0    1    0]
 [   0    1    3    1    0    0    0 1015    1    7]
 [   4    0    6    1    6    2   11    5  919   20]
 [   0    0    0    1   12    2    0    4    1  989]]
accuracy:  99.31
Iteration:  28600 	Average Loss:  0.0805886119500444
Iteration:  28700 	Average Loss:  0.3597771770465
Iteration:  28800 	Average Loss:  0.11230315520375585
Iteration:  28900 	Average Loss:  0.2403000540867596
Iteration:  29000 	Average Loss:  0.13264987427260005
ok 29000
[[ 970    0    0    0    4    0    5    1    0    0]
 [   0 1123    0    3    1    3    2    0    3    0]
 [   0    0 1020    2    3    0    0    6    1    0]
 [   1    0    1  996    0    6    0    4    2    0]
 [   0    0    0    0  977    0    0    0    1    4]
 [   1    0    0    4    0  881    3    1    2    0]
 [   1    1    1    0    3    1  951    0    0    0]
 [   1    2    3    2    0    0    0 1010    2    8]
 [   4    0    1    1    1    3    5    0  958    1]
 [   3    0    0    4   11    8    0    6    3  974]]
accuracy:  99.52
Iteration:  29100 	Average Loss:  0.09818294146494427
Iteration:  29200 	Average Loss:  0.27644142373256764
Iteration:  29300 	Average Loss:  0.13574119763420892
Iteration:  29400 	Average Loss:  0.24426679231788154
Iteration:  29500 	Average Loss:  0.13033085386584278
ok 29500
[[ 973    1    0    0    5    0    0    1    0    0]
 [   0 1134    0    1    0    0    0    0    0    0]
 [   1    8 1018    0    1    0    0    3    1    0]
 [   1    1    1 1002    0    0    0    3    2    0]
 [   0    2    0    0  972    0    0    1    1    6]
 [   1    0    0   21    0  863    1    2    4    0]
 [   5   11    1    1    6    0  932    0    2    0]
 [   0    5    4    1    0    0    0 1014    3    1]
 [   5    0    2    1    0    0    1    2  962    1]
 [   2    0    0    4    5   12    0   16    6  964]]
accuracy:  99.47
Iteration:  29600 	Average Loss:  0.21336629862958698
Iteration:  29700 	Average Loss:  0.1185043665220759
Iteration:  29800 	Average Loss:  0.10151725830740219
Iteration:  29900 	Average Loss:  0.12631062531870352
Writing snapshot to model_iter_30000.mdl
Iteration:  30000 	Average Loss:  0.13961949953589525
ok 30000
[[ 969    0    1    0    3    0    3    1    1    2]
 [   0 1119    1    4    0    0    1    7    3    0]
 [   0    0  996    4    0    0    0   32    0    0]
 [   1    0    0 1005    0    0    0    3    1    0]
 [   0    0    1    0  955    0    3    4    1   18]
 [   1    0    0   20    0  865    2    1    2    1]
 [   3    4    0    0    1    3  944    0    3    0]
 [   0    1    0    1    0    0    0 1023    1    2]
 [   3    0    1    4    1    0    2    4  953    6]
 [   1    0    0    5    6    0    0   11    0  986]]
accuracy:  99.48
Epoch time:  1484.1712186336517
