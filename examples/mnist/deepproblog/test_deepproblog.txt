--------------/home/amngobibin/Bureau/NeurASP/examples/mnist/deepproblog
Training for 1 epochs (30000 iterations).
ok
Epoch 1
[[  12    0    0    0    0    0    0    0  968    0]
 [ 127    0    0    0    0    0    0    0 1008    0]
 [ 131    0    0    0    0    0    0    0  901    0]
 [  95    0    0    0    0    0    0    0  915    0]
 [ 242    0    0    0    0    0    0    0  740    0]
 [  96    0    0    0    0    0    0    0  796    0]
 [ 255    0    0    0    0    0    0    0  703    0]
 [  36    0    0    0    0    0    0    0  992    0]
 [ 218    0    0    0    0    0    0    0  756    0]
 [  74    0    0    0    0    0    0    0  935    0]]
accuracy:  89.91
Iteration:  100 	Average Loss:  2.808664814305278
Iteration:  200 	Average Loss:  2.816477059956382
Iteration:  300 	Average Loss:  2.792052221946783
Iteration:  400 	Average Loss:  2.6004038144946646
Iteration:  500 	Average Loss:  2.4267011277009423
ok 500
[[  64  896    0    0    0    0    0   19    0    1]
 [   0 1074    0    0    0   43    0   14    4    0]
 [   0  930    7    0    0   38    0   48    0    9]
 [   0  680    6    0    0  185    0  102   18   19]
 [   0   20    0    0    0  610    0    9   16  327]
 [   0   98    0    0    0  435    0  144   29  186]
 [   0   68    0    0    0  831    0   11   32   16]
 [   0   55    0    0    0    8    0  951    0   14]
 [   1   63    0    0    0  109    0  342   73  386]
 [   0   18    0    0    0   24    0  245    4  718]]
accuracy:  87.51
Iteration:  600 	Average Loss:  2.235401343924274
Iteration:  700 	Average Loss:  2.2151949378656224
Iteration:  800 	Average Loss:  1.9767989210957333
Iteration:  900 	Average Loss:  1.8546812172348541
Iteration:  1000 	Average Loss:  1.4478438494917247
ok 1000
[[ 921    1   13    8    0    2    5   21    9    0]
 [   0 1053   32   13    8    5    0    3   21    0]
 [   1    6  902   41   19    3    2   42   13    3]
 [   7    0   22  738   27  115   14   36   48    3]
 [   0    1    6    9  767    0  165    1   18   15]
 [   7    1    1   12   44  490  183   27  127    0]
 [   8    0    0   10    2   18  917    0    3    0]
 [   0    4   26    4    5    1    0  971   13    4]
 [   2    4    3   20   36   51   40  109  703    6]
 [   4    0    0    1   74   10    2  138  207  573]]
accuracy:  95.33
Iteration:  1100 	Average Loss:  1.3289561249661022
Iteration:  1200 	Average Loss:  1.3317903742221828
Iteration:  1300 	Average Loss:  0.7801520875080442
Iteration:  1400 	Average Loss:  0.822227263164751
Iteration:  1500 	Average Loss:  0.4739677015136621
ok 1500
[[ 948    0    8    2    0    0    7    4    7    4]
 [   0 1119    1   12    1    0    0    0    2    0]
 [   1   11  933   50    2    0    1   17   16    1]
 [   5    0   12  971    0    4    0    7    6    5]
 [   0    2   19    3  900    0    5    0    7   46]
 [   8    1    1  112    8  656   11    7   82    6]
 [  15    4   13    3   13   20  879    0   11    0]
 [   0    3   22   37    0    1    0  922    3   40]
 [   5    7    1   36    4   14    3   10  863   31]
 [   4    2    1   10   17    5    1    7   19  943]]
accuracy:  98.00999999999999
Iteration:  1600 	Average Loss:  0.511685470849509
Iteration:  1700 	Average Loss:  0.9103279191292742
Iteration:  1800 	Average Loss:  0.43618885861412776
Iteration:  1900 	Average Loss:  0.6752438172163515
Iteration:  2000 	Average Loss:  0.5666138179932219
ok 2000
[[ 958    1    4    0    1    1    6    6    3    0]
 [   0 1128    3    4    0    0    0    0    0    0]
 [   1    7  965    7    8    0    1   36    7    0]
 [   7    2   40  927    1    1    0   25    7    0]
 [   0    3    3    0  964    0    1    0    3    8]
 [  12    1    1  167   22  620   14    8   47    0]
 [  14    4    2    0   24    5  904    0    5    0]
 [   0   13   30    2    3    0    0  970    2    8]
 [  10    9    6   28    7    3    6   12  887    6]
 [   6    9    3   10   51    2    1   26   25  876]]
accuracy:  98.45
Iteration:  2100 	Average Loss:  0.768867093795695
Iteration:  2200 	Average Loss:  0.4775817527885582
Iteration:  2300 	Average Loss:  0.5348992125375331
Iteration:  2400 	Average Loss:  0.25847499892014514
Iteration:  2500 	Average Loss:  0.6836925519013473
ok 2500
[[ 974    1    0    0    0    0    2    1    2    0]
 [   2 1122    2    5    1    0    3    0    0    0]
 [  19   15  964   18    4    0    1    6    5    0]
 [  12    1    9  977    1    1    0    2    6    1]
 [   2    2    4    4  941    0    7    1    1   20]
 [  15    0    1  209    3  641   14    1    8    0]
 [  26    1    0    1    8    6  915    0    1    0]
 [   8    9   55   18    2    0    0  931    1    4]
 [  18    5    1   34    2   12    5   10  871   16]
 [  15    3    2   23    8    5    0   20    6  927]]
accuracy:  98.77
Iteration:  2600 	Average Loss:  0.5724670355044147
Iteration:  2700 	Average Loss:  0.36490384348901345
Iteration:  2800 	Average Loss:  0.42317348857304077
Iteration:  2900 	Average Loss:  0.5584826966008457
Iteration:  3000 	Average Loss:  0.26426754373500677
ok 3000
[[ 961    0    0    1    3    3    4    5    2    1]
 [   0 1119    2    5    0    0    0    8    1    0]
 [   6    4  955    9    8    1    0   48    1    0]
 [   1    0    7  947    2    8    0   28    9    8]
 [   0    0    3    0  960    0    3    3    1   12]
 [   4    0    1   12    3  804    5    7   44   12]
 [   9    2    1    1   26    3  913    0    3    0]
 [   0    3   12    0    0    0    0 1007    1    5]
 [   6    2    3    7    3    3    4    8  926   12]
 [   2    1    0    2   16    4    0   21   15  948]]
accuracy:  98.89
Iteration:  3100 	Average Loss:  0.24924330148657062
Iteration:  3200 	Average Loss:  0.4644979059473323
Iteration:  3300 	Average Loss:  0.38235078643599524
Iteration:  3400 	Average Loss:  0.37402927617003356
Iteration:  3500 	Average Loss:  0.2842334481286556
ok 3500
[[ 961    0   10    0    1    0    1    3    3    1]
 [   0 1109    7    5    0    0    1    2   11    0]
 [   1    2 1005    9    0    0    0   13    2    0]
 [   7    0   15  952    0   11    0   17    7    1]
 [   0    2   14    0  927    0    2    1    2   34]
 [  10    0    1    5    0  863    5    6    2    0]
 [  14    2    8    0   19    6  907    0    2    0]
 [   0    3   29    6    0    1    0  982    1    6]
 [   7    0    5    8    1   22    3    6  916    6]
 [   3    2    0    2    6    8    0   18   17  953]]
accuracy:  98.96000000000001
Iteration:  3600 	Average Loss:  0.18066133932521428
Iteration:  3700 	Average Loss:  0.32897046619769055
Iteration:  3800 	Average Loss:  0.2899764608835895
Iteration:  3900 	Average Loss:  0.30690957124046625
Iteration:  4000 	Average Loss:  0.376376027015012
ok 4000
[[ 944    0    0    1    3    1   26    3    2    0]
 [   0 1112    2    8    1    0    5    7    0    0]
 [   4    0  985   13    3    1    0   22    4    0]
 [   1    0    3  987    2    4    0    9    3    1]
 [   0    0    0    1  969    0    2    1    0    9]
 [   2    0    1   19    0  858    7    3    2    0]
 [   2    1    1    1   17    4  931    0    1    0]
 [   0    1   16    9    2    1    0  986    3   10]
 [   6    0    3   25    2   27    6   12  874   19]
 [   3    1    0    8   16    9    0   14    4  954]]
accuracy:  99.06
Iteration:  4100 	Average Loss:  0.24050842331623434
Iteration:  4200 	Average Loss:  0.4838401948762609
Iteration:  4300 	Average Loss:  0.2932232504409555
Iteration:  4400 	Average Loss:  0.4782179467709359
Iteration:  4500 	Average Loss:  0.2172856229971911
ok 4500
[[ 966    0    0    0    0    1    8    3    2    0]
 [   0 1102    6    6    1    1    3    9    7    0]
 [   3    0  999   13    1    1    0   11    4    0]
 [   1    0    3  975    1   16    0    8    4    2]
 [   0    0    4    0  949    0    7    1    0   21]
 [   4    0    0    6    0  875    4    2    1    0]
 [   6    1    0    1    6    7  937    0    0    0]
 [   1    0   28    8    0    1    0  979    1   10]
 [   6    0    3    7    4   34   12    5  893   10]
 [   3    1    0    4   10   10    1    9    6  965]]
accuracy:  99.13
Iteration:  4600 	Average Loss:  0.2657098647330669
Iteration:  4700 	Average Loss:  0.3857601786571794
Iteration:  4800 	Average Loss:  0.33781689006058824
Iteration:  4900 	Average Loss:  0.30043267713873084
Iteration:  5000 	Average Loss:  0.1872908947046883
ok 5000
[[ 957    1   16    1    0    0    0    3    2    0]
 [   0 1127    1    6    0    0    0    1    0    0]
 [   1    7 1009    8    1    0    0    6    0    0]
 [   0    0   10  991    1    2    0    4    1    1]
 [   0    1    4    0  958    0    1    0    0   18]
 [   5    0    1   39    1  842    1    1    1    1]
 [  33    7    4    1   19   21  873    0    0    0]
 [   0    3   40   19    1    0    0  953    1   11]
 [   4    5   10   36    4   27    1    5  854   28]
 [   6    2    0   10    8    8    0    7    0  968]]
accuracy:  99.0
Iteration:  5100 	Average Loss:  0.14430415717024403
Iteration:  5200 	Average Loss:  0.19122936077381208
Iteration:  5300 	Average Loss:  0.17353903671759593
Iteration:  5400 	Average Loss:  0.33354849770034667
Iteration:  5500 	Average Loss:  0.2814536998306896
ok 5500
[[ 938    0   13    1    3    4    4    1   13    3]
 [   0 1108    2    5    4    0    1    1   14    0]
 [   0    0 1004   12    8    1    0    4    3    0]
 [   0    0    6  983    1    9    0    2    6    3]
 [   0    0    0    0  950    0    1    0    3   28]
 [   1    0    1   13    0  865    5    1    6    0]
 [  10    3    0    0   14    3  923    0    5    0]
 [   0    3   24   19    1    3    0  949    5   24]
 [   1    0    4    4    2    4    2    0  955    2]
 [   2    2    0    4    5    2    0    4   29  961]]
accuracy:  98.92
Iteration:  5600 	Average Loss:  0.21006058030696842
Iteration:  5700 	Average Loss:  0.2734681632836746
Iteration:  5800 	Average Loss:  0.22238862210719915
Iteration:  5900 	Average Loss:  0.2695240788794533
Iteration:  6000 	Average Loss:  0.22520835394796423
ok 6000
[[ 964    0    1    1    0    4    5    2    3    0]
 [   0 1091    1    4    0    6    2    9   22    0]
 [   2    5  989   18    0    1    3   13    1    0]
 [   0    0    2  980    0   17    0    6    4    1]
 [   0    0    4    0  857    5   11   10    3   92]
 [   2    0    0    3    0  883    2    1    1    0]
 [   3    1    0    1    2   30  921    0    0    0]
 [   1    0   18    6    0    3    0  994    3    3]
 [   2    0    1    7    0   40    2    6  914    2]
 [   3    0    0    4    1   13    2   16    8  962]]
accuracy:  98.55000000000001
Iteration:  6100 	Average Loss:  0.4002617934817742
Iteration:  6200 	Average Loss:  0.22079117128722026
Iteration:  6300 	Average Loss:  0.33400339624778996
Iteration:  6400 	Average Loss:  0.32068065645473093
Iteration:  6500 	Average Loss:  0.3155846996292913
ok 6500
[[ 955    0    0    0    0    1   21    1    2    0]
 [   0 1110    4    4    2    0    8    1    6    0]
 [   1    1 1014    4    6    1    1    1    3    0]
 [   1    0    1  965    1   16    0    3   13   10]
 [   0    1    1    0  952    0   14    0    2   12]
 [   1    0    0    4    0  852   14    1   17    3]
 [   2    1    0    0    3    1  951    0    0    0]
 [   0    3   26    1    1    1    0  948   19   29]
 [   2    0    1    2    2    0    7    0  958    2]
 [   1    0    0    1    8    3    4    4   40  948]]
accuracy:  98.83
Iteration:  6600 	Average Loss:  0.3689820340905542
Iteration:  6700 	Average Loss:  0.4035281445627962
Iteration:  6800 	Average Loss:  0.311443126519621
Iteration:  6900 	Average Loss:  0.38320526549168776
Iteration:  7000 	Average Loss:  0.13437331852382872
ok 7000
[[ 971    0    0    0    0    0    5    2    2    0]
 [   0 1123    5    5    1    0    0    0    1    0]
 [   2    0 1022    2    0    0    0    5    1    0]
 [   0    0    4  990    0    3    0    5    7    1]
 [   0    0    9    0  960    0    5    1    0    7]
 [   2    0    1   12    0  867    3    1    6    0]
 [   7    4    2    1    6    4  931    0    3    0]
 [   0    2   31    2    3    0    0  981    3    6]
 [   2    0    3    3    2    2    3    1  945   13]
 [   3    2    0    4   15    4    0    5    5  971]]
accuracy:  99.35000000000001
Iteration:  7100 	Average Loss:  0.2814517084425774
Iteration:  7200 	Average Loss:  0.15079053886049248
Iteration:  7300 	Average Loss:  0.22483342708046006
Iteration:  7400 	Average Loss:  0.19991536743562283
Iteration:  7500 	Average Loss:  0.3491811604275181
ok 7500
[[ 965    0    2    0    0    0    8    2    3    0]
 [   0 1130    1    2    0    0    1    1    0    0]
 [   2   24  995    1    0    0    0    9    1    0]
 [   1    2    3  994    0    1    0    5    4    0]
 [   0    3    6    0  946    0    4    1    1   21]
 [   2    1    1   33    0  834    2    1    4   14]
 [   6    3    1    0    5    6  936    0    1    0]
 [   0    7   21    4    0    0    0  987    2    7]
 [   4    5    4   10    1    6    2    3  927   12]
 [   2    3    0   10    2    2    0    8    5  977]]
accuracy:  99.14
Iteration:  7600 	Average Loss:  0.17160334658553483
Iteration:  7700 	Average Loss:  0.41848209787456125
Iteration:  7800 	Average Loss:  0.2847909522368274
Iteration:  7900 	Average Loss:  0.2865938229033601
Iteration:  8000 	Average Loss:  0.20878115033395228
ok 8000
[[ 936    0    1    0    1    4   32    4    2    0]
 [   0 1128    1    3    0    1    2    0    0    0]
 [   0    6 1007    0    1    0    1   16    1    0]
 [   3    1    2  976    0   16    0    5    5    2]
 [   0    4    4    0  957    0   11    1    1    4]
 [   0    0    1    3    0  883    4    1    0    0]
 [   1    2    2    0    2    5  946    0    0    0]
 [   0    8   16    1    0    0    0  994    3    6]
 [   3    2    2    3    1   16   11    6  928    2]
 [   1    4    0    0   12   12    1   12   11  956]]
accuracy:  99.33
Iteration:  8100 	Average Loss:  0.24137948450942123
Iteration:  8200 	Average Loss:  0.27089272655725616
Iteration:  8300 	Average Loss:  0.42973101250995394
Iteration:  8400 	Average Loss:  0.22769148232079625
Iteration:  8500 	Average Loss:  0.21842244027660151
ok 8500
[[ 963    0    2    0    3    0    3    5    4    0]
 [   0 1128    1    2    0    0    1    3    0    0]
 [   0    2 1002    0    1    0    0   24    3    0]
 [   1    0   20  959    1    3    0   15    7    4]
 [   0    1    1    0  976    0    1    1    1    1]
 [   1    0    1   10    0  827    4    1   44    4]
 [   5    2    2    0   13    1  926    0    9    0]
 [   0    3   16    0    2    0    0 1002    2    3]
 [   2    0    3    3    4    2    1    5  951    3]
 [   2    2    0    2   84    0    0   12   12  895]]
accuracy:  98.71
Iteration:  8600 	Average Loss:  0.19642222733526174
Iteration:  8700 	Average Loss:  0.2411785415956698
Iteration:  8800 	Average Loss:  0.1880259581862225
Iteration:  8900 	Average Loss:  0.40119267092552774
Iteration:  9000 	Average Loss:  0.2975669329434368
ok 9000
[[ 968    1    1    0    2    0    3    1    2    2]
 [   0 1132    0    1    0    0    0    1    1    0]
 [   1    7  992    4   10    1    0   16    1    0]
 [   1    0    3  992    0    4    0    6    2    2]
 [   0    2    0    0  976    0    1    0    1    2]
 [   3    1    1   14    0  862    3    1    5    2]
 [  13    7    0    0    7    1  927    0    3    0]
 [   0    8   12    0    2    0    0  988    4   14]
 [   5    2    4    3    3    5    3    2  938    9]
 [   3    3    0    6   10    5    0    6    9  967]]
accuracy:  99.27
Iteration:  9100 	Average Loss:  0.3229073884496307
Iteration:  9200 	Average Loss:  0.2988675554021385
Iteration:  9300 	Average Loss:  0.2200456617941
Iteration:  9400 	Average Loss:  0.10968979724992677
Iteration:  9500 	Average Loss:  0.1108222797536797
ok 9500
[[ 967    0    2    1    0    1    3    3    3    0]
 [   0 1118    1    6    0    0    1    5    4    0]
 [   1    2 1000   14    0    0    0   14    1    0]
 [   0    0    0  999    0    4    0    3    3    1]
 [   0    0    4    0  953    0    3    2    0   20]
 [   1    0    1    8    0  876    4    1    1    0]
 [  10    2    1    1    2    3  937    0    2    0]
 [   0    1   13    4    0    0    0 1001    2    7]
 [   1    0    2   11    3    7    1    2  939    8]
 [   4    1    1   10    4    6    0    6    6  971]]
accuracy:  99.26
Iteration:  9600 	Average Loss:  0.16012446428431662
Iteration:  9700 	Average Loss:  0.34012915358710766
Iteration:  9800 	Average Loss:  0.25905158227624514
Iteration:  9900 	Average Loss:  0.185145417040905
Writing snapshot to model_iter_10000.mdl
Iteration:  10000 	Average Loss:  0.2842896618561114
ok 10000
[[ 957    0    4    0    0    2   14    1    2    0]
 [   0 1126    2    1    0    0    2    0    4    0]
 [   0    1 1020    3    0    0    0    7    1    0]
 [   0    0    2  988    0   13    0    6    0    1]
 [   0    1    3    0  949    0    8    2    3   16]
 [   0    0    0    7    0  874    2    1    7    1]
 [   3    1    0    0    2    4  946    0    2    0]
 [   0    2   44    2    0    0    0  964    4   12]
 [   1    1    5    3    0    7    2    1  953    1]
 [   3    2    0    2    3    9    0    6   33  951]]
accuracy:  99.11
Iteration:  10100 	Average Loss:  0.1476246948893695
Iteration:  10200 	Average Loss:  0.18615586574483245
Iteration:  10300 	Average Loss:  0.18665467196728014
Iteration:  10400 	Average Loss:  0.1650169203143489
Iteration:  10500 	Average Loss:  0.22722974816568497
ok 10500
[[ 973    0    1    0    0    0    3    1    2    0]
 [   1 1112   11    0    0    0    6    0    5    0]
 [   1    1 1028    0    0    0    0    2    0    0]
 [   0    0   24  965    0    9    0    4    7    1]
 [   0    3   12    0  945    0    6    2    2   12]
 [   2    0    1   10    0  849    2    1   27    0]
 [   9    1    2    0    4    1  936    0    5    0]
 [   1    6   58    0    0    0    0  958    2    3]
 [   3    0   13    0    1    0    0    1  955    1]
 [   5    3    2    4    8    4    0   16   41  926]]
accuracy:  99.0
Iteration:  10600 	Average Loss:  0.4014191085226721
Iteration:  10700 	Average Loss:  0.27417838922507864
Iteration:  10800 	Average Loss:  0.35238767351038314
Iteration:  10900 	Average Loss:  0.2415253037747926
Iteration:  11000 	Average Loss:  0.2316498414954063
ok 11000
[[ 970    1    1    0    0    0    4    1    3    0]
 [   0 1127    4    2    0    0    1    1    0    0]
 [   2    3 1022    0    0    0    0    5    0    0]
 [   0    0    9  990    0    4    0    3    3    1]
 [   1    2   10    0  930    0   10    1    2   26]
 [   1    0    1    9    0  871    4    1    3    2]
 [   8    2    0    0    2    3  942    0    1    0]
 [   0    6   22    4    0    1    0  984    1   10]
 [   3    0    3    2    1    3    1    4  945   12]
 [   3    4    1    4    3    5    0    6    2  981]]
accuracy:  99.21
Iteration:  11100 	Average Loss:  0.27120677149234484
Iteration:  11200 	Average Loss:  0.1508408014309274
Iteration:  11300 	Average Loss:  0.10035883750670554
Iteration:  11400 	Average Loss:  0.13804450189604422
Iteration:  11500 	Average Loss:  0.22717239517128
ok 11500
[[ 973    0    0    0    0    0    2    3    2    0]
 [   0 1123    0    5    1    0    1    3    0    2]
 [   2    1  996    2    0    0    0   30    1    0]
 [   0    0    0 1001    0    1    0    8    0    0]
 [   0    0    2    0  922    0    6   10    0   42]
 [   2    0    1   29    0  854    2    2    2    0]
 [  10    2    1    1    2    2  935    0    5    0]
 [   0    1    6    3    0    0    0 1011    1    6]
 [   3    0    1    8    0    1    1    7  935   18]
 [   2    1    0   11    2    1    1   19    0  972]]
accuracy:  98.95
Iteration:  11600 	Average Loss:  0.25965854013939815
Iteration:  11700 	Average Loss:  0.16991797615702325
Iteration:  11800 	Average Loss:  0.06779286594085343
Iteration:  11900 	Average Loss:  0.29076632430425237
Iteration:  12000 	Average Loss:  0.09784216329080796
ok 12000
[[ 972    0    0    0    2    0    4    1    1    0]
 [   0 1130    4    0    0    0    1    0    0    0]
 [   1    1 1029    0    1    0    0    0    0    0]
 [   0    1   11  978    0   11    0    1    7    1]
 [   0    0    1    0  961    0    9    0    2    9]
 [   1    0    1    4    0  881    3    0    2    0]
 [   5    2    2    0    4    3  941    0    1    0]
 [   1    8   53    2    0    2    0  953    3    6]
 [   3    0    5    1    1    4    2    0  958    0]
 [   1    3    0    6   13   14    1    7   27  937]]
accuracy:  99.11999999999999
Iteration:  12100 	Average Loss:  0.24866512945784183
Iteration:  12200 	Average Loss:  0.1493354031098287
Iteration:  12300 	Average Loss:  0.19998982344257743
Iteration:  12400 	Average Loss:  0.21587173883591684
Iteration:  12500 	Average Loss:  0.37777624257381076
ok 12500
[[ 963    0    0    0    0    0   10    3    2    2]
 [   1 1116    9    0    1    0    4    4    0    0]
 [   2    0 1022    4    0    0    0    4    0    0]
 [   0    1    2  976    0   16    0   10    3    2]
 [   1    0    5    1  870    0   13    8    0   84]
 [   0    0    1    2    0  885    3    1    0    0]
 [   3    1    1    1    1   17  934    0    0    0]
 [   0    2   14    0    0    0    0 1006    1    5]
 [   1    1    3    4    0   40    2    3  900   20]
 [   1    3    0    1    4    4    0   11    0  985]]
accuracy:  98.63
Iteration:  12600 	Average Loss:  0.25501570689319847
Iteration:  12700 	Average Loss:  0.28306052230620915
Iteration:  12800 	Average Loss:  0.3013398935587896
Iteration:  12900 	Average Loss:  0.1346296481568821
Iteration:  13000 	Average Loss:  0.12008610766020715
ok 13000
[[ 971    1    0    0    0    0    0    6    2    0]
 [   0 1130    3    1    0    0    0    1    0    0]
 [   2    1 1017    5    0    0    0    4    3    0]
 [   0    1    0  995    0    4    0    5    4    1]
 [   0    0    0    0  963    0    2    5    0   12]
 [   3    0    1    2    0  881    3    1    1    0]
 [  13    3    1    0    3    2  931    1    4    0]
 [   0    2   14    6    1    0    0  998    4    3]
 [   3    0    2    2    2    3    1    1  952    8]
 [   4    2    0    4   12    2    0   22    4  959]]
accuracy:  99.26
Iteration:  13100 	Average Loss:  0.06744397394209745
Iteration:  13200 	Average Loss:  0.3455979195849828
Iteration:  13300 	Average Loss:  0.13388884520888358
Iteration:  13400 	Average Loss:  0.19952411246440507
Iteration:  13500 	Average Loss:  0.0652017804005944
ok 13500
[[ 963    4    1    0    0    0    8    2    2    0]
 [   0 1132    2    0    0    0    0    1    0    0]
 [   1    6 1017    0    3    0    0    3    2    0]
 [   2    0    9  985    0    1    0    8    5    0]
 [   0    5    0    0  967    0    5    1    1    3]
 [   4    2    1   14    0  855    9    1    6    0]
 [   5    4    2    0    9    2  934    0    2    0]
 [   0   15   19    1    1    0    0  987    4    1]
 [   2   16    2    2    2    1    2    2  943    2]
 [   1   11    0    4   12    2    0   13    9  957]]
accuracy:  99.42
Iteration:  13600 	Average Loss:  0.10757056154791256
Iteration:  13700 	Average Loss:  0.11805142878717868
Iteration:  13800 	Average Loss:  0.3433885486430328
Iteration:  13900 	Average Loss:  0.3384014086248207
Iteration:  14000 	Average Loss:  0.21520722423244373
ok 14000
[[ 968    0    1    0    0    0    6    3    2    0]
 [   0 1124    3    0    1    0    4    2    1    0]
 [   2    3 1005    3    0    0    1   17    1    0]
 [   0    0    4  979    0    5    0   18    4    0]
 [   0    1    4    0  936    0   18    9    0   14]
 [   2    0    1    5    0  871    9    2    2    0]
 [   9    1    2    0    1    1  944    0    0    0]
 [   0    2    5    0    0    0    0 1016    1    4]
 [   1    0    3    1    0    5    8    6  944    6]
 [   5    2    1    8    3   18    1   27    4  940]]
accuracy:  99.07000000000001
Iteration:  14100 	Average Loss:  0.1139834408310731
Iteration:  14200 	Average Loss:  0.15303544220463208
Iteration:  14300 	Average Loss:  0.2349297901973199
Iteration:  14400 	Average Loss:  0.14826582429970414
Iteration:  14500 	Average Loss:  0.2606847110360971
ok 14500
[[ 971    0    1    0    0    0    4    2    2    0]
 [   0 1129    0    0    1    0    4    1    0    0]
 [   3   30  985    5    1    0    2    6    0    0]
 [   0    1    1 1000    0    4    0    2    2    0]
 [   0    3    2    0  967    0    6    1    1    2]
 [   1    0    1    4    0  882    1    1    2    0]
 [   5    1    0    0    0    5  945    0    2    0]
 [   0    8   13    3    0    1    0  998    1    4]
 [   3    0    2    2    0    2    1    2  958    4]
 [   2    2    0   12   10   13    2   11    9  948]]
accuracy:  99.29
Iteration:  14600 	Average Loss:  0.1823869792813072
Iteration:  14700 	Average Loss:  0.16407960462352583
Iteration:  14800 	Average Loss:  0.07488251611449889
Iteration:  14900 	Average Loss:  0.12034489721847669
Iteration:  15000 	Average Loss:  0.14043552629259368
ok 15000
[[ 971    0    2    0    0    0    1    3    3    0]
 [   0 1126    1    2    1    0    1    4    0    0]
 [   2    3 1004    3    2    0    0   10    8    0]
 [   0    0    1  999    0    3    0    3    3    1]
 [   0    0    0    0  974    0    0    1    0    7]
 [   0    0    1   11    0  877    0    1    2    0]
 [   7    2    2    0   17   40  888    0    2    0]
 [   0    2    8    2    0    1    0 1004    2    9]
 [   1    0    1    1    2    4    0    3  949   13]
 [   1    3    0    8    8    7    0    9   10  963]]
accuracy:  99.24
Iteration:  15100 	Average Loss:  0.3202192131491636
Iteration:  15200 	Average Loss:  0.22861751122745755
Iteration:  15300 	Average Loss:  0.24110393425702006
Iteration:  15400 	Average Loss:  0.14169502771963427
Iteration:  15500 	Average Loss:  0.3710146260793254
ok 15500
[[ 969    0    0    0    0    0    6    3    2    0]
 [   0 1109    0    4    0    1    4   12    5    0]
 [   1    7  974   17    2    1    0   21    9    0]
 [   0    0    0  953    0   46    0    4    6    1]
 [   0    0    0    0  961    0    3    5    1   12]
 [   0    0    1    0    0  884    1    1    5    0]
 [   4    1    2    0    2    5  939    0    5    0]
 [   0    1    5    2    0    1    0 1011    2    6]
 [   1    0    1    4    0    5    0    3  956    4]
 [   1    1    0    6    5   17    0    8    3  968]]
accuracy:  99.36
Iteration:  15600 	Average Loss:  0.2982349895522714
Iteration:  15700 	Average Loss:  0.24444018399935596
Iteration:  15800 	Average Loss:  0.14993377776937902
Iteration:  15900 	Average Loss:  0.12979063671395935
Iteration:  16000 	Average Loss:  0.108613555142414
ok 16000
[[ 975    0    0    0    0    0    2    2    1    0]
 [   0 1128    0    5    0    0    1    1    0    0]
 [   3    5 1018    0    1    1    0    3    1    0]
 [   0    0    1  992    0    8    0    3    5    1]
 [   0    1    1    0  949    0    3    4    1   23]
 [   1    0    1    5    0  880    2    1    2    0]
 [  11    2    1    0    2    2  939    0    1    0]
 [   0    1   16    3    0    0    0 1001    2    5]
 [   5    0    1    3    1    5    0    3  947    9]
 [   3    2    0    7    2    2    0    8    4  981]]
accuracy:  99.33999999999999
Iteration:  16100 	Average Loss:  0.1521151497380704
Iteration:  16200 	Average Loss:  0.28830321117876173
Iteration:  16300 	Average Loss:  0.12083314245628271
Iteration:  16400 	Average Loss:  0.29573356935910977
Iteration:  16500 	Average Loss:  0.21555682793868464
ok 16500
[[ 970    2    1    0    0    0    2    2    2    1]
 [   0 1130    0    1    0    0    1    1    2    0]
 [   1    2 1002    3    0    0    1   14    8    1]
 [   0    0    1  990    0    8    0    4    4    3]
 [   0    4    2    0  946    0    4    1    4   21]
 [   1    0    1    7    0  880    1    1    0    1]
 [   9    3    1    0    1   12  931    0    0    1]
 [   0    3   11    4    1    2    0  988    1   18]
 [   2    0    1    1    0    5    0    0  955   10]
 [   0    1    0    1    1    2    0    5    3  996]]
accuracy:  99.31
Iteration:  16600 	Average Loss:  0.16113228625921205
Iteration:  16700 	Average Loss:  0.15154071148317094
Iteration:  16800 	Average Loss:  0.25142966745416984
Iteration:  16900 	Average Loss:  0.13879403731882967
Iteration:  17000 	Average Loss:  0.14198925478380475
ok 17000
[[ 973    0    0    0    0    0    6    1    0    0]
 [   0 1120    2    2    3    1    6    1    0    0]
 [   5    0 1008    0    3    0    2   11    3    0]
 [   2    0    2  979    0   17    0    3    1    6]
 [   0    0    0    0  964    0    5    1    2   10]
 [   3    0    1    3    0  881    2    1    0    1]
 [  11    1    0    0    1    5  940    0    0    0]
 [   1    1    9    2    2    1    0 1004    1    7]
 [   5    0    2    3    2    8    2    2  934   16]
 [   3    1    0    1    1    2    0    8    2  991]]
accuracy:  99.42
Iteration:  17100 	Average Loss:  0.1392322167503712
Iteration:  17200 	Average Loss:  0.1200124171043474
Iteration:  17300 	Average Loss:  0.27276497798850646
Iteration:  17400 	Average Loss:  0.20225418797448697
Iteration:  17500 	Average Loss:  0.13720587924792146
ok 17500
[[ 975    0    0    0    0    0    0    1    4    0]
 [   0 1134    0    0    0    0    0    1    0    0]
 [   5    8 1007    0    3    0    0    8    1    0]
 [   3    9    1  962    0   17    0    6    6    6]
 [   0    3    0    0  970    0    1    1    0    7]
 [   5    6    1    1    0  871    2    2    4    0]
 [  17    3    0    0    4    2  931    0    1    0]
 [   0    9   10    0    1    0    0 1006    1    1]
 [   4    5    6    0    7    0    3    3  939    7]
 [   2    5    1    1   12    2    0   12    6  968]]
accuracy:  99.38
Iteration:  17600 	Average Loss:  0.1771747635554015
Iteration:  17700 	Average Loss:  0.1843669939955569
Iteration:  17800 	Average Loss:  0.24446341256446005
Iteration:  17900 	Average Loss:  0.16036776676785722
Iteration:  18000 	Average Loss:  0.342155815779527
ok 18000
[[ 968    0    0    0    0    0    6    2    3    1]
 [   0 1128    4    0    0    0    2    1    0    0]
 [   0    1 1028    1    0    0    0    2    0    0]
 [   0    0   11  986    0    5    0    1    6    1]
 [   0    0    4    0  970    0    4    0    2    2]
 [   2    1    1    5    0  858   15    1    8    1]
 [   6    3    1    0    1    1  946    0    0    0]
 [   0    8   32    1    2    0    0  970    7    8]
 [   4    0    9    2    1    0    5    0  953    0]
 [   3    3    1    6   11    1    0    4   14  966]]
accuracy:  99.44
Iteration:  18100 	Average Loss:  0.2606763310323916
Iteration:  18200 	Average Loss:  0.1107029891519723
Iteration:  18300 	Average Loss:  0.13588393953121033
Iteration:  18400 	Average Loss:  0.30168027656189894
Iteration:  18500 	Average Loss:  0.197346425192923
ok 18500
[[ 975    0    0    0    0    0    2    1    2    0]
 [   0 1130    1    0    1    0    2    1    0    0]
 [   5    0 1015    2    2    0    1    6    1    0]
 [   0    1    1  955    0   33    0    7    9    4]
 [   0    0    0    0  977    0    1    0    1    3]
 [   1    0    0    1    0  887    1    1    1    0]
 [  10    2    0    0    1    7  938    0    0    0]
 [   0    2   14    1    0    0    0 1005    2    4]
 [   3    0    3    1    0    5    0    1  957    4]
 [   2    2    0    0    8    5    0    7   10  975]]
accuracy:  99.51
Iteration:  18600 	Average Loss:  0.13039656693236665
Iteration:  18700 	Average Loss:  0.06221068941757912
Iteration:  18800 	Average Loss:  0.07494315336608631
Iteration:  18900 	Average Loss:  0.06473365495579382
Iteration:  19000 	Average Loss:  0.06941597727063184
ok 19000
[[ 972    0    0    0    0    1    3    1    3    0]
 [   0 1125    2    2    1    0    1    1    3    0]
 [   3    1 1023    2    0    0    0    3    0    0]
 [   0    0    1  999    0    2    0    3    4    1]
 [   0    0    1    0  974    0    1    0    2    4]
 [   2    0    0   49    0  834    3    1    3    0]
 [   9    3    0    0    1    1  943    0    1    0]
 [   1    1   20    6    1    0    0  981    3   15]
 [   3    0    3    3    0    1    1    0  960    3]
 [   3    2    0    4    7    2    1    3    7  980]]
accuracy:  99.48
Iteration:  19100 	Average Loss:  0.1632721864265535
Iteration:  19200 	Average Loss:  0.3038389420810978
Iteration:  19300 	Average Loss:  0.3507790945144125
Iteration:  19400 	Average Loss:  0.08675963409986784
Iteration:  19500 	Average Loss:  0.10085823107680789
ok 19500
[[ 975    0    0    0    0    0    1    0    4    0]
 [   0 1131    2    0    1    0    1    0    0    0]
 [   6    1 1020    4    1    0    0    0    0    0]
 [   1    2    6  987    0    5    0    2    7    0]
 [   0    0    0    0  979    0    0    0    0    3]
 [   2    1    0   13    2  797    1    1   69    6]
 [   9    4    1    0   13    1  891    0   39    0]
 [   1    7   27    4    9    0    0  970    5    5]
 [   0    0    6    1    1    0    0    0  966    0]
 [   3    3    1    1   17    1    0    4   10  969]]
accuracy:  99.46000000000001
Iteration:  19600 	Average Loss:  0.18683026424575178
Iteration:  19700 	Average Loss:  0.11063757937700876
Iteration:  19800 	Average Loss:  0.16886254287353733
Iteration:  19900 	Average Loss:  0.10635829896538983
Writing snapshot to model_iter_20000.mdl
Iteration:  20000 	Average Loss:  0.1966890734323521
ok 20000
[[ 938    1    4    1    3    6   19    2    5    1]
 [   0 1125    1    3    0    0    5    1    0    0]
 [   0    1 1016   11    0    0    1    3    0    0]
 [   0    0    2 1003    0    2    0    3    0    0]
 [   0    0    1    0  971    0    4    1    1    4]
 [   1    0    0   16    0  870    2    1    2    0]
 [   3    3    0    0    2    5  945    0    0    0]
 [   0    6   29   10    0    1    0  979    1    2]
 [   0    0    8   23    0    7    3    2  930    1]
 [   1    2    1    8    8    5    1    6    7  970]]
accuracy:  99.53
Iteration:  20100 	Average Loss:  0.1927541360179611
Iteration:  20200 	Average Loss:  0.21878770324439376
Iteration:  20300 	Average Loss:  0.14621940437445452
Iteration:  20400 	Average Loss:  0.2262925861805505
Iteration:  20500 	Average Loss:  0.055555963215494025
ok 20500
[[ 973    2    0    0    0    0    3    1    1    0]
 [   0 1131    1    0    1    0    1    1    0    0]
 [   6    9  993    7    0    0    0   15    2    0]
 [   0    1    2  989    0    9    0    5    3    1]
 [   0    0    2    0  971    0    0    0    0    9]
 [   2    0    0    5    1  863    3    3    5   10]
 [   8    2    2    0    7    2  933    0    4    0]
 [   1    4    4    3    1    0    0 1006    1    8]
 [   1    0    5    6    2    2    2    2  926   28]
 [   2    2    1    5    7    1    1    6    0  984]]
accuracy:  99.19
Iteration:  20600 	Average Loss:  0.11911311334669886
Iteration:  20700 	Average Loss:  0.1675889733764758
Iteration:  20800 	Average Loss:  0.13380480814893883
Iteration:  20900 	Average Loss:  0.2226004095456818
Iteration:  21000 	Average Loss:  0.13691553101194404
ok 21000
[[ 972    2    0    0    0    0    1    3    2    0]
 [   0 1132    1    1    0    0    0    1    0    0]
 [   7    3  989    4    0    0    0   28    1    0]
 [   0    0    1  998    0    3    0    6    2    0]
 [   3    0    3    0  950    0    2    1    2   21]
 [   2    1    0   18    0  861    2    2    6    0]
 [  26    3    0    0    3    3  919    0    4    0]
 [   0    3    7    2    1    0    0 1011    3    1]
 [   4    0    3    1    3    2    1    2  956    2]
 [   6    2    0    5    4    0    0   14   12  966]]
accuracy:  99.33
Iteration:  21100 	Average Loss:  0.2996524153668956
Iteration:  21200 	Average Loss:  0.07217874665397744
Iteration:  21300 	Average Loss:  0.12271913524389319
Iteration:  21400 	Average Loss:  0.1054510137440045
Iteration:  21500 	Average Loss:  0.1007505927236383
ok 21500
[[ 972    0    0    0    0    0    4    1    3    0]
 [   1 1126    1    0    0    1    4    0    2    0]
 [   6    1 1011    0    1    0    2    1   10    0]
 [   0    1   10  982    0    5    0    3    8    1]
 [   0    0    0    0  975    0    1    0    3    3]
 [   2    0    0    3    0  880    2    1    1    3]
 [   8    1    0    0    3    3  941    0    2    0]
 [   1    7   15    0    3    0    0  991    9    2]
 [   1    0    2    0    2    0    1    1  965    2]
 [   3    2    2    3   15    0    1    9   24  950]]
accuracy:  99.3
Iteration:  21600 	Average Loss:  0.10619421543925435
Iteration:  21700 	Average Loss:  0.17038350638391186
Iteration:  21800 	Average Loss:  0.1565260692676075
Iteration:  21900 	Average Loss:  0.1943808361120155
Iteration:  22000 	Average Loss:  0.2120826069819833
ok 22000
[[ 977    0    0    0    0    0    1    1    1    0]
 [   0 1127    0    3    0    0    4    1    0    0]
 [   7    5 1001    2    1    0    2   12    2    0]
 [   0    0    2 1002    0    0    0    2    3    1]
 [   3    1    0    0  936    0    6    0    3   33]
 [   3    0    0   26    0  853    1    1    8    0]
 [  15    1    0    0    2    7  928    0    5    0]
 [   1    9    5    2    1    1    0  988    5   16]
 [   6    0    3    2    2    1    0    1  951    8]
 [   4    3    0    4    3    2    0    6    6  981]]
accuracy:  99.14
Iteration:  22100 	Average Loss:  0.08640618636781032
Iteration:  22200 	Average Loss:  0.17344119114591686
Iteration:  22300 	Average Loss:  0.2025962369287196
Iteration:  22400 	Average Loss:  0.11241845037687083
Iteration:  22500 	Average Loss:  0.14568122121298865
ok 22500
[[ 975    0    1    0    0    0    2    1    1    0]
 [   0 1121    5    4    0    0    4    1    0    0]
 [   1    0 1031    0    0    0    0    0    0    0]
 [   1    0   11  986    0    7    0    3    1    1]
 [   0    1    5    0  939    0    6    4    1   26]
 [   1    0    1    6    0  882    1    1    0    0]
 [  11    1    0    0    2    6  938    0    0    0]
 [   0    1   31    1    0    1    0  988    1    5]
 [   7    0   15    1    1    2    0    5  930   13]
 [   3    3    4    5    3    3    0    5    1  982]]
accuracy:  99.28
Iteration:  22600 	Average Loss:  0.22367288489294337
Iteration:  22700 	Average Loss:  0.16779827438883038
Iteration:  22800 	Average Loss:  0.15333634366954357
Iteration:  22900 	Average Loss:  0.1095592355386355
Iteration:  23000 	Average Loss:  0.08451929284541146
ok 23000
[[ 976    0    0    0    0    0    1    1    2    0]
 [   0 1123    0    5    0    1    5    1    0    0]
 [   6    2 1003    8    1    0    3    7    2    0]
 [   0    0    1  998    0    5    0    2    2    2]
 [   0    1    0    0  965    0    5    0    4    7]
 [   3    0    0    7    0  878    2    0    2    0]
 [  11    2    0    0    4    2  939    0    0    0]
 [   1    2   10    2    0    1    0  999    1   12]
 [   6    0    2    2    0    2    2    1  954    5]
 [   3    3    0    2    6   11    0    4    5  975]]
accuracy:  99.4
Iteration:  23100 	Average Loss:  0.10654377392383667
Iteration:  23200 	Average Loss:  0.032238192981293295
Iteration:  23300 	Average Loss:  0.12181207273862209
Iteration:  23400 	Average Loss:  0.20397799994441868
Iteration:  23500 	Average Loss:  0.22741079987926383
ok 23500
[[ 972    2    3    0    0    0    0    1    2    0]
 [   0 1132    0    2    0    0    0    1    0    0]
 [   1    4 1014    6    1    0    0    6    0    0]
 [   0    0    0 1000    0    2    0    2    2    4]
 [   0    0    0    0  972    0    2    0    0    8]
 [   2    0    1   14    0  874    1    0    0    0]
 [  24    3    2    2    5    4  917    0    1    0]
 [   1    2    4    3    6    1    0 1002    1    8]
 [   1    1    1    4    3    4    1    5  941   13]
 [   4    3    0    0   13    3    0    2    0  984]]
accuracy:  99.42
Iteration:  23600 	Average Loss:  0.20464174631432566
Iteration:  23700 	Average Loss:  0.1874235367925345
Iteration:  23800 	Average Loss:  0.21664408501344184
Iteration:  23900 	Average Loss:  0.07616003453148366
Iteration:  24000 	Average Loss:  0.1974718703666996
ok 24000
[[ 976    1    0    0    0    0    0    1    2    0]
 [   0 1121    2    4    0    2    2    4    0    0]
 [   3    7 1013    5    0    0    2    2    0    0]
 [   0    0    1  998    0    5    0    2    2    2]
 [   4    0    2    0  898    0   15    1    0   62]
 [   4    0    0    7    0  878    2    0    1    0]
 [  11    2    0    0    1    3  941    0    0    0]
 [   1    1   10    8    0    1    0  999    1    7]
 [   1    0    2    2    0    0    3    0  955   11]
 [   5    2    1    3    3    4    1    3    1  986]]
accuracy:  98.95
Iteration:  24100 	Average Loss:  0.2206507270721503
Iteration:  24200 	Average Loss:  0.15508278077707133
Iteration:  24300 	Average Loss:  0.14121383915499192
Iteration:  24400 	Average Loss:  0.23823971255837365
Iteration:  24500 	Average Loss:  0.026104987370823805
ok 24500
[[ 976    0    0    0    0    0    1    1    2    0]
 [   0 1130    0    1    0    1    2    1    0    0]
 [   4    9  987    6    1    0    4   13    8    0]
 [   0    0    0  992    0    5    0    4    8    1]
 [   0    0    0    0  970    0    8    0    1    3]
 [   2    0    0    3    0  872    5    1    9    0]
 [  10    2    0    0    1    2  941    0    2    0]
 [   1    7    2    2    1    0    0 1009    4    2]
 [   2    0    1    1    0    0    2    0  967    1]
 [   3    2    0    1    6    3    1    8   27  958]]
accuracy:  99.42
Iteration:  24600 	Average Loss:  0.04407198955848528
Iteration:  24700 	Average Loss:  0.11831558776032713
Iteration:  24800 	Average Loss:  0.06668376998346905
Iteration:  24900 	Average Loss:  0.186123121889868
Iteration:  25000 	Average Loss:  0.11934458667129429
ok 25000
[[ 979    0    0    0    0    0    0    0    1    0]
 [   0 1133    0    0    0    0    1    1    0    0]
 [   6    2 1019    0    1    0    2    2    0    0]
 [   3    1   14  967    0    4    0    3   18    0]
 [   4    2    2    0  956    0   10    0    1    7]
 [   3    0    0    3    0  879    4    0    3    0]
 [  18    3    0    0    1    1  934    0    1    0]
 [   3    7   24    0    2    0    0  986    5    1]
 [   2    0    2    1    0    0    1    0  968    0]
 [  15    3    2    2    6    8    1    3   25  944]]
accuracy:  99.27
Iteration:  25100 	Average Loss:  0.109920939477449
Iteration:  25200 	Average Loss:  0.24902547775786893
Iteration:  25300 	Average Loss:  0.13708038463307548
Iteration:  25400 	Average Loss:  0.14443469834893555
Iteration:  25500 	Average Loss:  0.09536925068559801
ok 25500
[[ 965    0    6    0    0    1    2    2    4    0]
 [   0 1128    1    0    0    0    1    2    3    0]
 [   0    3 1022    0    0    0    0    6    1    0]
 [   0    1    2  985    0   10    0    8    3    1]
 [   0    3    5    0  958    0    1    0    3   12]
 [   1    0    0    2    0  885    1    1    2    0]
 [  11    3    2    0    4   10  925    0    3    0]
 [   1    2    7    0    1    0    0 1011    1    5]
 [   0    0    2    1    0    3    0    0  965    3]
 [   2    2    1    3    5    2    0    5    5  984]]
accuracy:  99.53999999999999
Iteration:  25600 	Average Loss:  0.0788927915993804
Iteration:  25700 	Average Loss:  0.21523916180844785
Iteration:  25800 	Average Loss:  0.021977502283497485
Iteration:  25900 	Average Loss:  0.15752363606711772
Iteration:  26000 	Average Loss:  0.07745577208511051
ok 26000
[[ 975    0    2    0    0    0    1    1    1    0]
 [   0 1121    2    5    0    0    1    3    3    0]
 [   1    0 1025    2    1    0    0    3    0    0]
 [   0    0    1 1001    0    1    0    5    0    2]
 [   0    1    4    0  948    0    4    2    3   20]
 [   1    0    0   38    0  850    1    1    1    0]
 [  11    2    1    2    2    3  937    0    0    0]
 [   1    1    9    3    1    0    0 1003    1    9]
 [   2    0    1    8    0    9    1    1  948    4]
 [   3    2    0   16    3    3    0    4    0  978]]
accuracy:  99.33999999999999
Iteration:  26100 	Average Loss:  0.0698068759478798
Iteration:  26200 	Average Loss:  0.11884736120444883
Iteration:  26300 	Average Loss:  0.12823876849676588
Iteration:  26400 	Average Loss:  0.16609540087274122
Iteration:  26500 	Average Loss:  0.013458551312056264
ok 26500
[[ 979    0    0    0    0    0    0    1    0    0]
 [   0 1128    0    3    0    1    1    2    0    0]
 [   9    2  999    7    5    0    0   10    0    0]
 [   0    0    1  990    0    6    0    8    1    4]
 [   0    2    0    0  969    0    3    0    1    7]
 [   1    0    0    5    0  881    2    1    1    1]
 [  16    2    0    2    4    1  932    0    1    0]
 [   1    2    3    1    1    0    0 1016    1    3]
 [   5    0    1    2    0    2    2    1  956    5]
 [   6    3    0    0    7    3    0    8    3  979]]
accuracy:  99.5
Iteration:  26600 	Average Loss:  0.0799029584672182
Iteration:  26700 	Average Loss:  0.17749065499281755
Iteration:  26800 	Average Loss:  0.05234530617344924
Iteration:  26900 	Average Loss:  0.17802154978739432
Iteration:  27000 	Average Loss:  0.34009411075554286
ok 27000
[[ 966    1    2    1    0    4    1    2    3    0]
 [   0 1121    1    2    0    2    0    4    5    0]
 [   0    4  934   24    1    1    0   63    5    0]
 [   0    0    0  985    0   11    0    9    1    4]
 [   2    2    2    0  935    5    3    3    0   30]
 [   1    0    0    7    0  880    1    1    0    2]
 [  12    5    0    1    2   67  850    0   21    0]
 [   0    0    0    1    0    0    0 1019    1    7]
 [   1    0    0    1    0   13    0    2  935   22]
 [   1    3    0    0    4    3    0    6    0  992]]
accuracy:  99.18
Iteration:  27100 	Average Loss:  0.19728956139586507
Iteration:  27200 	Average Loss:  0.09887991286899567
Iteration:  27300 	Average Loss:  0.3283637484516799
Iteration:  27400 	Average Loss:  0.26362522938627364
Iteration:  27500 	Average Loss:  0.11099507504045247
ok 27500
[[ 973    1    0    0    0    0    1    2    3    0]
 [   0 1130    0    1    0    1    1    2    0    0]
 [   2   11  979    0    1    0    3   31    5    0]
 [   0    1    0  975    0   22    0    7    4    1]
 [   1    0    1    0  966    0    2    3    0    9]
 [   1    0    0    1    0  887    2    1    0    0]
 [  10    2    0    0    2    4  939    0    1    0]
 [   0    2    0    0    0    1    0 1023    1    1]
 [   1    0    1    3    3   12    1    5  940    8]
 [   0    3    0    0   12   15    0    9    0  970]]
accuracy:  99.42
Iteration:  27600 	Average Loss:  0.3220772397190843
Iteration:  27700 	Average Loss:  0.20948999423850911
Iteration:  27800 	Average Loss:  0.0892977602471508
Iteration:  27900 	Average Loss:  0.18860895044326317
Iteration:  28000 	Average Loss:  0.1992838456288591
ok 28000
[[ 973    1    2    0    0    0    0    1    3    0]
 [   1 1128    0    2    0    0    1    3    0    0]
 [   0    2 1010    0    0    0    2   17    1    0]
 [   0    0    2 1002    0    1    0    5    0    0]
 [   3    0    1    0  960    1    5    4    0    8]
 [   1    0    1   32    0  855    2    1    0    0]
 [  15    2    0    1    1    1  936    0    2    0]
 [   0    1    3    1    1    0    0 1021    0    1]
 [   2    0    6    6    2    7    0    5  941    5]
 [   2    3    0    9   15   14    0   15    0  951]]
accuracy:  99.28
Iteration:  28100 	Average Loss:  0.22455615132877518
Iteration:  28200 	Average Loss:  0.17665373410036037
Iteration:  28300 	Average Loss:  0.07390076819884803
Iteration:  28400 	Average Loss:  0.11408698599231898
Iteration:  28500 	Average Loss:  0.14242600153997356
ok 28500
[[ 961    1    0    0    0    5    6    2    4    1]
 [   0 1130    0    0    1    1    1    1    1    0]
 [   3    7 1003    0    3    0    0   12    4    0]
 [   0    2    1  935    0   51    0    9    9    3]
 [   0    0    0    0  977    0    0    1    0    4]
 [   0    0    0    0    0  889    2    1    0    0]
 [   4    2    0    1   12    6  931    0    2    0]
 [   0    2    3    0    1    0    0 1021    1    0]
 [   0    0    0    0    2   17    2    5  945    3]
 [   0    3    0    0   32   20    0   23    7  924]]
accuracy:  99.03999999999999
Iteration:  28600 	Average Loss:  0.10064201959039525
Iteration:  28700 	Average Loss:  0.1372233085893908
Iteration:  28800 	Average Loss:  0.11555482624853498
Iteration:  28900 	Average Loss:  0.24786920780155672
Iteration:  29000 	Average Loss:  0.14595768024873396
ok 29000
[[ 920    1    2    0    0    8   40    2    3    4]
 [   0 1127    2    2    0    1    2    1    0    0]
 [   0    0 1025    3    0    0    0    3    1    0]
 [   0    0    1  989    0   16    0    1    2    1]
 [   0    0    3    0  949    0    3    0    0   27]
 [   0    0    0    1    0  887    4    0    0    0]
 [   0    2    2    0    3    2  947    0    2    0]
 [   0    5   16   13    0    1    0  978    1   14]
 [   0    0    1    5    0    6    3    1  955    3]
 [   0    2    0    0    0    8    1    1    3  994]]
accuracy:  99.36
Iteration:  29100 	Average Loss:  0.0653317605672058
Iteration:  29200 	Average Loss:  0.4711726047524207
Iteration:  29300 	Average Loss:  0.15571523838868281
Iteration:  29400 	Average Loss:  0.13631067798495025
Iteration:  29500 	Average Loss:  0.10758725017654332
ok 29500
[[ 974    1    0    0    0    1    1    1    2    0]
 [   0 1131    0    1    0    1    1    1    0    0]
 [   4    5 1002    7    0    0    1   11    2    0]
 [   0    0    1 1001    0    5    0    0    2    1]
 [   1    7    2    0  945    0    9    0    1   17]
 [   1    0    0    6    0  883    2    0    0    0]
 [  10    3    0    1    1    1  942    0    0    0]
 [   0   13    3    3    0    0    0 1007    1    1]
 [   3    0    0    3    0    1    3    1  960    3]
 [   2    5    0    2    2    6    0    8    6  978]]
accuracy:  99.47
Iteration:  29600 	Average Loss:  0.09506895338354654
Iteration:  29700 	Average Loss:  0.19720375609089985
Iteration:  29800 	Average Loss:  0.08876348211339807
Iteration:  29900 	Average Loss:  0.10573101434848507
Writing snapshot to model_iter_30000.mdl
Iteration:  30000 	Average Loss:  0.10127955049076025
ok 30000
[[ 974    2    0    0    0    0    0    3    1    0]
 [   0 1127    1    4    0    0    1    2    0    0]
 [   3    1 1015    1    0    0    1   10    1    0]
 [   0    0    1  999    0    2    0    3    4    1]
 [   3    0    1    0  945    0   11    1    0   21]
 [   1    0    0   11    0  877    2    1    0    0]
 [  12    4    0    0    1    2  939    0    0    0]
 [   0    1    3    1    0    0    0 1019    1    3]
 [   2    0    1    2    1    5    1    3  951    8]
 [   2    3    0    2    4    6    0    8    2  982]]
accuracy:  99.4
Epoch time:  1396.4284934997559
